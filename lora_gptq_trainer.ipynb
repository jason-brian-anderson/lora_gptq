{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78437d00-0dfd-420f-9d1d-accf9a2cde82",
   "metadata": {},
   "source": [
    "The goal of this notebook is to distill down the essential compenents of training HF models in a way that is easy to port to a data pipeline and apply to new model training scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff4105b-66b9-43ed-81d8-9769e56f1df8",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5186aef3-01b0-4a1f-ad6e-9c99d46ca824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from huggingface_hub import login\n",
    "import os\n",
    "import pandas as pd\n",
    "from rich import print\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f647f4-e46c-4b7d-bb28-4e11e6d632ab",
   "metadata": {},
   "source": [
    "# Define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b85d9c78-ef0c-4d91-a9df-bd9c799da50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42 #reproducability  over training runs\n",
    "clobber_project_dir = False #wipe the project director clean\n",
    "project_dir = \"chat_summarizer\" #project name, also used as wandb project name\n",
    "\n",
    "#creds\n",
    "hf_token = os.environ[\"HF_TOKEN\"]\n",
    "wandb_key = os.environ[\"WANDB_KEY\"]\n",
    "hf_account_name = os.environ[\"HF_ACCOUNT_NAME\"]\n",
    "\n",
    "#HF touchpoints\n",
    "hf_dataset_name = \"knkarthick/dialogsum\"\n",
    "source_hf_model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "destination_hf_model_name = f\"{hf_account_name}/llama2-7b-dialogsum-qlora-gptq\"\n",
    "checkpoint_dir = \"best_checkpoint\"\n",
    "quantization_dir = 'quantized_8bit'\n",
    "merged_dir = 'merged_model'\n",
    "quantized_train_dir = 'quant_trained_model'\n",
    "project_path = os.path.join(project_dir, checkpoint_dir)\n",
    "quant_path = os.path.join(project_dir, quantization_dir)\n",
    "quantized_train_path = os.path.join(project_dir, quantized_train_dir)\n",
    "\n",
    "train_test_split_ratio = 0.1\n",
    "\n",
    "#LoRA hparams\n",
    "lora_r = 64  # rank\n",
    "lora_alpha = lora_r * 2\n",
    "lora_dropout = 0.05\n",
    "\n",
    "#training hparams\n",
    "epochs = 2\n",
    "per_device_train_batch_size=8\n",
    "gradient_accumulation_steps=4\n",
    "early_stopping_patience = 3\n",
    "learning_rate = 3e-4\n",
    "logging_steps = 25\n",
    "device = \"cuda\"\n",
    "max_training_sample_length = 2048\n",
    "\n",
    "#quantization params\n",
    "quantization_bits = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d0fc97-fbe3-4097-9751-3feafcbf218b",
   "metadata": {},
   "source": [
    "## State of working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07ffbb7b-ca53-4226-a31f-407e141bc587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">chat_summarizer\n",
       "</pre>\n"
      ],
      "text/plain": [
       "chat_summarizer\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\n",
      "0 drwxr-xr-x 1 root root 4096 Nov  5 04:48 runs\n",
      "0 drwxr-xr-x 1 root root 4096 Nov  5 10:18 checkpoint-500\n",
      "0 drwxr-xr-x 1 root root 4096 Nov  5 12:28 best_checkpoint\n",
      "0 drwxr-xr-x 1 root root 4096 Nov  5 17:35 quantized\n",
      "0 drwxr-xr-x 1 root root 4096 Nov  6 08:53 quantized_8bit\n",
      "0 drwxr-xr-x 1 root root 4096 Nov  6 20:57 .\n",
      "0 drwxr-xr-x 1 root root 4096 Nov  6 21:07 quant_trained_model\n",
      "0 drwxr-xr-x 1 root root 4096 Nov  7 00:43 ..\n"
     ]
    }
   ],
   "source": [
    "print(project_dir)\n",
    "!mkdir -p $project_dir\n",
    "\n",
    "#Set clobber_project_dir to True to reset working directory\n",
    "if clobber_project_dir:\n",
    "    !rm -rf ./$project_dir\n",
    "\n",
    "!ls -latrs ./$project_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77d175a-1860-4ae4-a387-97981d2b3466",
   "metadata": {},
   "source": [
    "## Initiate wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "256352b0-c7c7-45a3-9e5a-2e25fcae01cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import wandb\n",
    "\n",
    "#wandb.login(key = wandb_key)\n",
    "#run = wandb.init(project=project_dir, job_type=\"training\", anonymous=\"allow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98c44be-3cb1-45d4-ba26-5fa6a1e39e46",
   "metadata": {},
   "source": [
    "# Process data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "274adcda-c2a1-4524-b964-75b69186daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "\n",
    "def generate(text, model, temp=0.7,max_new_tokens = 24):\n",
    "    from transformers import TextStreamer\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=False)\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to('cuda')\n",
    "\n",
    "    # Call the generate method of the model with the given inputs and additional generation configurations.\n",
    "    outputs = model.generate(**inputs,  # \"inputs\" likely includes input_ids or prompts for generation.\n",
    "                           streamer=streamer,  # \"streamer\" not a standard parameter in HF documentation, likely custom for model-specific streaming.\n",
    "                           max_new_tokens=max_new_tokens,  # Sets the maximum number of new tokens to generate; range varies based on model and computational limits.\n",
    "                           temperature=temp,  # Controls randomness: lower->more deterministic, higher->more random; typically in range [0.5, 1.5].\n",
    "                           do_sample=True,  # Enables sampling; when True, picks tokens based on probability distribution, rather than just most likely.\n",
    "                           top_p=0.1,  # Nucleus sampling: selects top p% probability tokens for sampling; range [0, 1].\n",
    "                           top_k=40,  # Top-k sampling: chooses from top k probability tokens; if k=0, it's the same as using no top-k.\n",
    "                           repetition_penalty=1.23,  # Penalizes repeated tokens; >1 discourages, <1 encourages repetition; typically close to 1.\n",
    "                           typical_p=1,  # Typical sampling; selects tokens whose cumulative probability is above this threshold, range [0, 1], usually close to 1.\n",
    "                           guidance_scale=1,  # Affects the scale of guidance in models that support it, like CTRL; standard range not well-defined.\n",
    "                           #seed=seed,  # Sets a seed for reproducibility; commented out, so not in use.\n",
    "                          )\n",
    "    generated_tokens = outputs[0].tolist()[len(inputs[0]):]\n",
    "    result = tokenizer.decode(generated_tokens)\n",
    "    return result\n",
    "\n",
    "def set_plot_appearance(fontsize_title=14, \n",
    "                        fontsize_label=12, \n",
    "                        fontsize_ticks=8, \n",
    "                        theme='dark'):\n",
    "    \"\"\"\n",
    "    Configure the plot's appearance with font sizes and theme for dark backgrounds.\n",
    "    \n",
    "    Parameters:\n",
    "    fontsize_title: Font size for the title.\n",
    "    fontsize_label: Font size for the x and y labels.\n",
    "    fontsize_ticks: Font size for the x and y tick labels.\n",
    "    theme: Seaborn theme for the plot's aesthetic style.\n",
    "    \"\"\"\n",
    "    sns.set_theme(style=theme, palette='pastel')\n",
    "    \n",
    "    plt.rcParams.update({\n",
    "        'figure.facecolor': '#1a1a1a',  # Very dark grey background for the figure\n",
    "        'axes.facecolor': '#1a1a1a',    # Very dark grey background for the plots\n",
    "        'grid.color': 'gray',           # Lighter grey grid lines (less contrast)\n",
    "        'text.color': 'white',          # White text for better contrast on dark bg\n",
    "        'axes.labelcolor': 'white',     # White labels for axes\n",
    "        'xtick.color': 'white',         # White x-tick labels\n",
    "        'ytick.color': 'white',         # White y-tick labels\n",
    "        'axes.labelsize': fontsize_label,\n",
    "        'axes.titlesize': fontsize_title,\n",
    "        'xtick.labelsize': fontsize_ticks,\n",
    "        'ytick.labelsize': fontsize_ticks,\n",
    "        'legend.title_fontsize': fontsize_ticks + 2,\n",
    "        'legend.fontsize': fontsize_ticks,\n",
    "        'axes.edgecolor': 'lightgrey',  # Light grey color for the axes' spines\n",
    "    })\n",
    "# Possible modern themes: 'darkgrid', 'whitegrid', 'dark', 'white', and 'ticks'.\n",
    "# Example usage: set_plot_appearance(theme='ticks')\n",
    "\n",
    "def plot_text_length_histogram(df, bucket_size=64, percentile=95):\n",
    "    \"\"\"\n",
    "    Plot a histogram of text lengths and indicate the percentile.\n",
    "\n",
    "    Parameters:\n",
    "    df: the pandas dataframe to render from\n",
    "    bucket_size: the number of characters to bucket the histogram with\n",
    "    percentile: draws a vertical line at this percentile to visualize whether an acceptable fraction of the data lenghts are being used for training set\n",
    "    \"\"\"\n",
    "    set_plot_appearance()  # Apply appearance settings to the plot\n",
    "    text_lengths = df['text'].apply(len)  # Calculate text lengths.\n",
    "    bins = range(0, max(text_lengths) + bucket_size, bucket_size)  # Define histogram bins.\n",
    "    percentile_value = np.percentile(text_lengths, percentile)  # Calculate percentile value.\n",
    "\n",
    "    fig, ax = plt.subplots()  # Create figure and axis objects.\n",
    "    ax.hist(text_lengths, bins=bins, edgecolor='black', alpha=0.7)  # Plot histogram.\n",
    "    ax.axvline(x=percentile_value, color='red', linestyle='--')  # Draw percentile line.\n",
    "    \n",
    "    # Annotate the percentile line.\n",
    "    ax.text(percentile_value, ax.get_ylim()[1]*0.9, f' {percentile}th Percentile: {int(round(percentile_value, -1))}',\n",
    "            color='red', ha='left')\n",
    "\n",
    "    ax.set_xlabel('Text Length')  # Set x-axis label.\n",
    "    ax.set_ylabel('Frequency')  # Set y-axis label.\n",
    "    ax.set_title('Histogram of Text Lengths')  # Set title.\n",
    "\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))  # Set major locator for x-axis.\n",
    "    plt.show()  # Display the plot.\n",
    "\n",
    "def visualize_train_test_category_splits(train_df, test_df, top_x=5, normalize=True):\n",
    "    \"\"\"\n",
    "    Visualize the frequency of top categories in training and test datasets.\n",
    "    \"\"\"\n",
    "    set_plot_appearance()  # Apply appearance settings to the plot\n",
    "\n",
    "    # Get top x categories from both datasets.\n",
    "    train_topic_norm = train_df['topic'].value_counts(normalize=normalize).head(top_x)\n",
    "    test_topic_norm = test_df['topic'].value_counts(normalize=normalize).head(top_x)\n",
    "    \n",
    "    # Prepare the data for plotting.\n",
    "    train_topics = pd.DataFrame({'topic': train_topic_norm.index, 'frequency': train_topic_norm.values, 'dataset': 'Training'})\n",
    "    test_topics = pd.DataFrame({'topic': test_topic_norm.index, 'frequency': test_topic_norm.values, 'dataset': 'Test'})\n",
    "    combined_topics = pd.concat([train_topics, test_topics])\n",
    "\n",
    "    sns.barplot(x='frequency', y='topic', hue='dataset', data=combined_topics)  # Create bar plot.\n",
    "    plt.title('Top {} Topics Frequency Comparison'.format(top_x))  # Set title.\n",
    "    plt.xlabel('Normalized Frequency')  # Set x-axis label.\n",
    "    plt.ylabel('Topic')  # Set y-axis label.\n",
    "    plt.tight_layout()  # Adjust layout.\n",
    "    plt.show()  # Display the plot.\n",
    "\n",
    "\n",
    "\n",
    "def get_data_stuff(dataset_name, split_ratio=0.2):    \n",
    "    # %%\n",
    "    from datasets import load_dataset\n",
    "    from datasets import Dataset\n",
    "    import pandas as pd\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    \n",
    "    \n",
    "    #load the dataset\n",
    "    dataset = load_dataset(dataset_name)\n",
    "    \n",
    "    # Shuffle the dataset (setting seed for reproducibility)\n",
    "    shuffled_ds = dataset['train']#.shuffle(seed=seed)\n",
    "    #shuffled_ds = shuffled_ds.select(range(1000))\n",
    "\n",
    "    \n",
    "    # Split the dataset into training and test sets with a test size of 20%\n",
    "    train_test_split = shuffled_ds.train_test_split(test_size=train_test_split_ratio, seed = seed)\n",
    "    \n",
    "    # The train/test datasets are now accessible as follows:\n",
    "    train_ds = train_test_split['train']\n",
    "    raw_train_df = pd.DataFrame(train_ds)\n",
    "    \n",
    "    test_ds = train_test_split['test']\n",
    "    raw_test_df = pd.DataFrame(test_ds)\n",
    "    \n",
    "    prepared_train_df = prepare_dataset(raw_train_df, \"train\")\n",
    "    prepared_test_df = prepare_dataset(raw_test_df, \"test\")\n",
    "\n",
    "    prepared_train_dataset = Dataset.from_pandas(prepared_train_df)\n",
    "    prepared_test_dataset = Dataset.from_pandas(prepared_test_df)\n",
    "    \n",
    "    print(f\"length of downloaded ds: {len(shuffled_ds)}\")\n",
    "    print(f\"length of train_ds: {len(prepared_train_dataset)}\")\n",
    "    print(f\"length of test_ds: {len(prepared_test_dataset)}\")\n",
    "    estimated_training_steps = epochs * len(prepared_train_dataset) / per_device_train_batch_size / gradient_accumulation_steps\n",
    "    print(f\"estimated training steps will be {estimated_training_steps}\")\n",
    "    return prepared_train_df, prepared_test_df, prepared_train_dataset, prepared_test_dataset\n",
    "\n",
    "\n",
    "def prepare_dataset(df, split=\"train\"):\n",
    "    text_col = []\n",
    "    instruction = \"\"\"Write a concise summary of the below input text.Ensure that responses covers the key points of the text.Only provide full sentence responses.\"\"\"  # change instuction according to the task\n",
    "    if split == \"train\":\n",
    "        for _, row in df.iterrows():\n",
    "            input_q = row[\"dialogue\"]\n",
    "            output = row[\"summary\"]\n",
    "            text = (\n",
    "                \"### Instruction: \\n\"\n",
    "                + instruction\n",
    "                + \"\\n### Input: \\n\"\n",
    "                + input_q\n",
    "                + \"\\n### Response :\\n\"\n",
    "                + output\n",
    "                + \"\\n### End\"\n",
    "            )  # keeping output column in training dataset\n",
    "            text_col.append(text)\n",
    "        df.loc[:, \"text\"] = text_col\n",
    "    else:\n",
    "        for _, row in df.iterrows():\n",
    "            input_q = row[\"dialogue\"]\n",
    "            text = (\n",
    "                \"### Instruction: \\n\"\n",
    "                + instruction\n",
    "                + \"\\n### Input: \\n\"\n",
    "                + input_q\n",
    "                + \"\\n### Response :\\n\"\n",
    "            )  # not keeping output column in test dataset\n",
    "            text_col.append(text)\n",
    "        df.loc[:, \"text\"] = text_col\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a764bbf-2d24-410d-9356-68f2153af13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">length of downloaded ds: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12460</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "length of downloaded ds: \u001b[1;36m12460\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">length of train_ds: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11214</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "length of train_ds: \u001b[1;36m11214\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">length of test_ds: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1246</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "length of test_ds: \u001b[1;36m1246\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">estimated training steps will be <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">700.875</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "estimated training steps will be \u001b[1;36m700.875\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df, test_df, train_dataset, test_dataset = get_data_stuff(hf_dataset_name, \n",
    "                                                                split_ratio=train_test_split_ratio,\n",
    "                                                               )\n",
    "text = test_df['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46b9d045-f3df-45b3-beea-92336c089d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">### Instruction: \n",
       "Write a concise summary of the below input text.Ensure that responses covers the key points of the text.Only \n",
       "provide full sentence responses.\n",
       "### Input: \n",
       "#Person1#: Mister Ewing said we should show up at the conference center at <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">4:00</span> o'clock, right?\n",
       "#Person2#: Yes, he especially asked us not to be late. Some of the people from our east york branch office are \n",
       "coming, and he wants to make a good impression on them. How are you getting there?\n",
       "#Person1#: I was thinking of taking my car, but I think I'm just going to take the underground, because there is \n",
       "construction on the highway. What about you?\n",
       "#Person2#: I'll be taking the underground as well. Why don't we go together? I've been to the conference center \n",
       "only once, and I'm not sure if I can find my way around there.\n",
       "### Response :\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "### Instruction: \n",
       "Write a concise summary of the below input text.Ensure that responses covers the key points of the text.Only \n",
       "provide full sentence responses.\n",
       "### Input: \n",
       "#Person1#: Mister Ewing said we should show up at the conference center at \u001b[1;92m4:00\u001b[0m o'clock, right?\n",
       "#Person2#: Yes, he especially asked us not to be late. Some of the people from our east york branch office are \n",
       "coming, and he wants to make a good impression on them. How are you getting there?\n",
       "#Person1#: I was thinking of taking my car, but I think I'm just going to take the underground, because there is \n",
       "construction on the highway. What about you?\n",
       "#Person2#: I'll be taking the underground as well. Why don't we go together? I've been to the conference center \n",
       "only once, and I'm not sure if I can find my way around there.\n",
       "### Response :\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe3b1874-38b3-406c-a9c3-ce34e42f1f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#to enhance training, consider rolling the shuffle dice until you get good consistency between training and test set categories.\n",
    "visualize_train_test_category_splits(train_df, test_df, top_x=5, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b8f0497-7b16-406e-b3dc-3f0c265fdc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk8AAAHLCAYAAADRDnw9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAABU70lEQVR4nO3dd3wU1cL/8c/spoeELCGUQCiPXFFRUB6Volz1IoogoFIUBSw/LIhYQEC5lntFRVAEuaLyiF4FkUtVBESqIkgRRWkiAopAQksI6WXL/P4g2Usq2Wyym4Xv+/XKi82c2Zkz2Unmyzlnzhjx8fEmIiIiIlIhFn9XQERERCSQKDyJiIiIeEDhSURERMQDCk8iIiIiHlB4EhEREfGAwpOIiIiIBxSeRERERDyg8CQiIiLiAYUnEREREQ8oPIlUkUmTJpGYmEjjxo39XRUpR69evfjqq6/Ys2cPiYmJ/POf//R3lcQD/fr1IzExkX79+vm7KnIeU3gSOUPjxo1JTEzkk08+KXOdDh06kJiYyGuvvVbl+500aVKVbVNK+t///V/efvttatWqxYwZM5g4cSJff/11qesOHz6cxMTECn8NHz68WuqcmJjIvHnzKvW+tWvXVkONql9lj1nEV4L8XQGRc8W4ceN4++23OXr0qL+rImXo3LkzFouFJ598kh9++KHcdTdu3MjEiROLLGvVqhVdu3Zlw4YNbNy4scT6InJ+UHgSqSLHjx/n+PHj/q6GlKN+/foAFQq4GzduLBGI+vXrR9euXdm4cSNvvvlmtdRRRGo+dduJVJGyxjx169aN+fPns23bNvbv38+PP/7If/7zH7p16wacviBv3rzZ/frMrqAOHTq4txMeHs6IESNYu3Yt+/fvZ+fOncyYMYMrr7yy1PrYbDbGjx/Ptm3b2LdvH0uXLqVr166ljhk5s9uwRYsWTJ8+nZ07dxY5nq5duzJ16lTWr1/Pvn372L17NwsXLnQfx5mKb+/jjz/ml19+YdeuXUydOhWbzQac7kabM2cOv/76K7t27eL1118nPDzco5/7lVdeyYwZM9i5cyf79+9n7dq1jBgxgrCwMPc6hV2td911FwCbN292/4yraozaxRdfzDvvvMPWrVv5448/2Lx5M2PHjnUfK5z+TH744Qf27NlDs2bNiry/eFlhnQE6duxY5Lyo6vE+wcHBPPTQQ3z11Vfs3buXPXv2sHDhQrp06VJi3cLzPCEhgQceeIC1a9fy+++/s3nzZp566ikMwyjxnrCwMP7+97+zZcsW9u/fz+rVq7n77rvdx1jY5enpMf/1r39l0aJF7Nu3j507dzJ58uQiP+9CHTt2ZObMmfz444/8/vvv/PzzzyxcuJB77rnH2x+dnKfU8iRSjQYNGsS4ceM4evQoX331FampqcTFxXH55ZfTtWtXvvzyS3bt2sX06dMZPHgwu3bt4quvvnK//9ChQwCEhoYyd+5c2rZty/bt25k+fTpxcXH07NmT6667jqFDh7JkyRL3+yIiIliwYAEtW7Zky5YtbNq0ifj4eN55551yx8E0a9aMxYsX8+uvvzJ37lxsNht2ux2AZ599lvz8fLZs2cKxY8eIjY3lpptu4v333+e5557j3//+d4ntJSQksGjRIrZv387s2bNp3bo1t912G/Hx8bz66qvMnj2bb7/9llmzZtGhQwfuvvtuLBYLI0aMqNDP99Zbb2Xq1Knk5+fzxRdfkJyczHXXXcfw4cO5/vrr6dOnD3l5eRw6dIiJEyfStWtXWrVqxfTp00lLSwMgPT29QvsqT5cuXXjvvfcwTZPly5eTlJTEhRdeyAMPPMD111/PrbfeSlpaGqmpqTzxxBPMnj2bt99+m9tuuw2HwwHAG2+8QcOGDXnyySc5cOAADoeDiRMnMmLECA4dOsTcuXPd+9u1a5fXdS4UEhLCrFmz6NixIzt37mT27NkEBwfTuXNnPvroI/7+97/z0UcflXjf888/T/v27Vm1ahXffPMNXbt25emnnyYkJITx48e717NYLMyYMYNrrrmGX375hc8++4yYmBheeOGFEi17hZ9TRY65S5cudO7cmVWrVvHDDz/Qrl07+vbtS9OmTbn99tvd6xUeR1paGitWrOD48ePUqVOHSy65hN69ezNr1qwq+knK+UThSaQUzZo1K3MAcEJCQoW3079/f/Ly8rjppptISUkpUlb4P+Rdu3bx/vvvu8NTad1BQ4YMoW3btixYsIDHH3/cvfyDDz5g8eLFjB8/nq+//pqsrCwAhg4dSsuWLfnkk08YPXq0e/25c+cyZ86cMut79dVX8+abb5YY6wMwcOBADh48WGTZiy++yKJFixg5ciSzZ88mNze3SHmHDh144YUX+OCDD9zLZsyY4b6gPfroo6xYsQKAoKAgli1bRu/evRk3bhzJycll1hOgVq1aTJgwAYfDQc+ePdm9ezcAr732GlOnTqVXr14MGTKEyZMnc/jwYd58800SEhJo1aoV77//PocPHy53+xVls9mYMmUKqamp9OrVy91yAtCzZ0/effddnn76aZ5//nkAvvvuO9555x2GDRvGqFGjePXVV7n33nvp2rUrn332mXugdGGdC4NEdXUTPvXUU3Ts2JFJkybxxhtvuJdHRkYyd+5cXnjhBZYtW8axY8eKvO/SSy/lxhtvdHdVT548mfXr13P//ffz5ptvukN3v379uOaaa1i9ejX33XcfLpcLgPfff59ly5YV2aYnx9ylSxf69OnjHrtmsViYM2cOHTt2pG3btmzduhWAO++8E4vFQr9+/fjll1+KbKO0ViqRilC3nUgpmjdvzogRI0r98rTLxOFwuFsXzpSamlrhbfTt25f8/HzGjRtXZPmuXbuYN28eMTExdO3a1b38jjvuIC8vj9dff73I+uvXr+ebb74pcz/Hjh1jypQppZYVD04A2dnZzJs3j9q1a3P55ZeXKP/jjz+KBCeARYsWueteGJzg9M9p6dKlBAcHc+GFF5ZZx0I333wztWvXZs6cOe7gBGCaJi+//DJ2u52+ffuedTve6tOnD9HR0YwbN65IcAL44osv2L59O7169Sqy/I033uCnn37ikUce4f777+f555/n4MGDPPPMM9Ve3zMZhsHAgQP5448/igQngKysLCZPnkxoaCi33HJLifdOnjy5yBi/1NRUVqxYQVRUFBdccIF7ee/evQEYP368OzgB7N27lwULFlS67p9//nmRQf8ul8sdPNu0aVNi/eLBvrDOIpWhlieRUnz99dcMGDCg1LIOHTowf/78Cm1n0aJFPP/886xevZrPP/+cDRs28P3335OZmVnhutSqVYtmzZrx22+/ceTIkRLlGzZsYMCAAbRq1YoFCxZQq1YtmjRpwp49e0ptvdmyZQvXX399qfv65Zdf3C0GxcXGxvLYY49xww030Lhx4xJjkwoHY5/pzFBTqPCCW1rXU2HrRmnbKu7SSy8FSr/LLSkpiYMHD3LBBRcQGRnpbpGrDm3btgXgiiuuoGnTpiXKQ0NDiY2NxWazuS/WDoeDoUOHsmLFCl5++WUcDgfDhg3z6LyoChdccAE2m41jx46V2tIaGxsLQIsWLUqU7dixo8SywvMzOjraveziiy8mKyur1M97y5YtZf6enc327dvL3H/t2rXdy7744gu6d+/OF198weeff8769evZvHmzgpN4ReFJpBq99957pKamMmjQIB5++GGGDBmC3W5n9erV/OMf/3CPaSpPVFQUQJndWIVhpFatWkXWL95NWKi87rCyymJiYvjyyy9p3Lgx33//PevWrSM9PR2n0+m+fT80NLTE+0oLA4WtcBkZGSXKnE4ncHoA89kUHu+JEydKLT927BgXXHABUVFR1RqeYmJiALj//vvLXS8iIqLIBfvPP//kl19+4eqrr2b79u1nnTqhOhTW/aKLLuKiiy4qc72IiIgSy0r7/Ao/W6vV6l4WFRVFUlJSqdst67OriPLOLYvlv50qS5Ys4f777+ehhx5i4MCB3H///bhcLjZs2MBLL71UpePH5Pyh8CRSzebMmcOcOXOw2WxcffXV3HbbbfTs2ZPmzZtz4403FunKKE3hRapu3bqllsfFxQH/vZgUrl/YalBcWduB011epbnrrrto3LgxEyZM4K233ipSNnTo0CJdhr5SeLyFx19cvXr1gNIv8lWpcPt/+9vf2LNnT4Xf9/DDD3P11Vdz8uRJ2rZty7333svHH39cXdUsVeHPcOnSpTz00EPVso+MjIwyz8WyPruqtmLFClasWEFkZCRXXXUVt9xyC/379+eTTz7huuuuq5KbBuT8ojFPIj6SmprK8uXLGTJkCOvXr6dly5Y0b94cwB2gzvwfe6HMzEwOHDhAs2bNaNCgQYnyjh07Av/tBsvMzOTgwYM0a9as1ItWWVMblKfwtvrly5eXKGvXrp3H26sKO3fuBCgynUOh+Ph4mjZtyoEDB6q11Qngp59+Ak5Pu1BRrVq1YvTo0ezbt4/OnTvz559/8vzzz5c61svpdJZ6XlSFvXv3kp6eTuvWrQkKqp7/S+/evZvIyEhatWpVoqysc7G6jjkrK4tvvvmG0aNHM3fuXOrVq8cVV1xR5fuRc5/Ck0g1Ku3CHhQU5O4uKRzEeurUKVwuFw0bNix1O/PmzSMkJIRnn322yPKLL76Yvn37kpaWVmSKg88++4zQ0FCefvrpEvW54YYbPD6OwjvTrr766iLLb7vtNjp37uzx9qrC8uXLSUtLo1+/fiVCx5gxYwgODvbJIz7mzJlDRkYGo0ePLjX8hIWFucdFwen5ut555x0AHn30UY4fP85jjz1GUFAQU6dOLdH9eerUqTLPC285nU5mzJhBQkICzz//fKkBqmXLlmW2HFXEwoULARg1alSROaAuuOAC+vTpU+p7qvKY27VrV6Qbr1BhC2xeXl6V7EfOL+q2E6lGH3zwAZmZmWzdupXDhw8THBxMp06daNmyJUuWLHHfnZWdnc3PP/9M+/btmTJlCr///jumaTJ//nwSExN599136dy5M3369KFFixasX7+eunXr0rNnT4KCgnjiiSeKtLBMnTqVbt26MWjQIFq2bMn3339Pw4YNufXWW1mxYgU33XTTWbsLz7RgwQIeffRRxo4dS8eOHTl8+DCXXHIJ1157LUuXLqV79+5V/rM7m8zMTEaNGsXUqVNZsmQJX3zxBSkpKXTq1Ik2bdqwdetW3n333Wqvx8mTJxk6dCjTpk1j5cqVfPPNN+zbt4+QkBASEhJo3749P/zwg3tg9EsvvUSLFi2KjLfZunUrkyZNYtSoUTz33HPuaQ3g9NQGPXv25IMPPmDnzp24XC5WrFhR6mD84urVq1fm8xJPnjzJ2LFjmThxIpdddhmDBw+mc+fObN68meTkZBo2bMhFF11Eq1at6NGjR5lj6M5mzpw59O7dmxtvvJEVK1awZs0aYmJi6NWrF+vWrSv1XPTmmIsbO3Ys9evX5/vvv+fw4cOYpslVV11F27Zt+fHHH/n+++8rdVxyflN4EqlGr732Gtdffz2XX345N954Izk5ORw4cIBnnnmG2bNnF1n3iSee4B//+AedO3fm9ttvx2Kx8P3335OYmEheXh79+vVj6NCh9OzZkwcffJCcnBw2btzIv/71L7Zs2VJkW1lZWdxxxx08++yz3HzzzbRu3ZrffvuNoUOH0rRpU2666SaPxgIdOXKEPn368Pe//51rr72WoKAgduzYwd133018fLxfwhOcHgxc2HJzyy23EB4ezuHDh5k0aRJTp071WavC6tWrufnmm3nkkUfo1KkTnTp1Ijs7myNHjjBnzhx360u3bt24++67Wbt2LdOmTSuyjSlTptCpUyf3rN2rVq0C4IUXXgDgmmuuoUuXLlitVo4cOVKhIBEdHV3m1BqHDh1i7Nix5OfnM2DAAPr370+fPn3o1q0bISEhJCcn89tvvzFz5sxKhZZCLpeLgQMH8vTTT9OrVy8GDx7Mn3/+yUsvvcSpU6e46aabSgz+9uaYi3v77be55ZZbuOyyy7j++uux2+0cPnyYl19+mY8//tij/0SIFDLi4+NLHyEqIuekKVOm0Lt3b6677jr27dvn7+rIeWzUqFE88cQTDBgwgK+//trf1RGpMI15EjlHFd5tdqb27dvTq1cv9u3bp+AkPlPaufiXv/yFBx54gFOnTpU6V5dITaZuO5Fz1MyZM8nNzWXXrl1kZ2dz4YUXcv311+N0Onnuuef8XT05j4wbN46EhAR++ukn0tLSaNasGTfeeCPBwcGMGDGi1Nm/RWoydduJnKMGDx7M7bffTtOmTalVqxbp6els2bKFt99+2317vYgv3H777QwcOJC//OUv7klLt23bxrRp08p9ULVITaXwJCIiIuIBjXkSERER8YDCk4iIiIgHNGC8ghYsWEBwcDAnT570d1VERESkgurUqYPdbqd3795Vtk2FpwoKDg6utudLiXjKABKcTgAOWa1o4KKISOmq49qt8FRBhS1O9913n38rIgKEu1zsO3oUgO4NGpBTyrO7REQEPvrooyrfpv7iioiIiHhA4UlERETEAzUqPL300kts2rSJxMREWrVq5V7evHlzFi1axLp161i6dCkXXnih12UigcxpGMwND2dueDhOw/B3dUREzis1KjwtXbqU22+/nUOHDhVZPn78eGbNmkWnTp145513mDRpktdlIoEs3zB4ymbjKZuNfIUnERGfqlHhafPmzRw5cqTIstjYWFq3bs2CBQuA0wErPj6eZs2aVbpMREREpLJqVHgqTXx8PMePH8dZcFs2QGJiIo0aNap0mUjAM03CXS7CXS4wNVGBiIgv1fjwJCIlhZsm+44eZd/Ro4QrPImI+FSNn+cpKSmJevXqYbVa3a1IjRo1IjExkYyMjEqViYiIiFRWjW95SklJYceOHe5p1bt3786RI0c4cOBApctEREREKsuIj4+vMW3+48ePp3PnzsTFxZGamkpmZibXXnstF1xwAZMmTcJms5GRkcHw4cP59ddfASpd5qnCGUo1w7jUBGfOMN5CM4yLiJSpOq7fNarbbvTo0aUu379/Pz179qzSMhEREZHK0H9XRURERDyg8CQiIiLigRrVbSciFeMyDJaEhblfi4iI7yg8iU84nU7MM+YjMgwDq9XqxxoFtjzD4OE6dfxdDRGR85K67aTaOZ1O8uxOzKAw91ee3Vlk9ncREZFAoZYnqXamaRIcFsGNfR4m2laX9NRkVs2fhunI9XfVREREPKbwJD4TbauLLa6hv6txTtA8TyIi/qO/uCIiIiIeUHgSERER8YDCk4iIiIgHFJ5ExGvzkpNZffy4v6sRcDrk5ZGYlESHvDz3skmpqWw6dsyPtRKRs9GAcZFzVF2nkzHp6XTOyyPS5WJfcDBv16rFkvDwUtfvmZPD4MxMLnY4sAN7g4KYEB3Nd6GhANR3OrknK4vl4eHsCg6u0rpuOnaMhDOmrki2WNgfFMT/RUbyVRn1DST3ZmWRYxjMjYjwd1XcLs/Pp192NlfY7VxstxMMNIqPL3VdT8+lQrOTk/lrfj7/jojguZiYEuV3ZWXxSFYWCQ4HR6xWPoiM5N+1alXB0YlUL4UnkXNQLZeLz5OTqety8UFkJMetVnrk5DAtNZWhpsnnxS7iw9PTeSozk6VhYcyNiCAIuMhup8EZgaa+08mIzEwOBwVVeXgC2BkUxLSCC2d9p5MB2dl8kJrKMy4XMyMjq3x/vjQoK4uTFkuJ8LQpJIT/adiQfD/U6W+5ufTPzmZ3cDAHrVYuKGPeNU/PpUK35OTwv3Z7mfsfkJXF+LQ0loaF8X+RkbTLz+fl9HTCTZN3oqKq5BhFqovCk0gAchkGqwtahEp7PMuA7GyaO530i411txzNiIhgcXIyL6SnszQ8HHvB+9rm5/NUZiYvRUfzvh//13/UamXhGRfi+RERfHf8OA9mZnodnkJNk3zArGGPsjENg7yzr1YtZkRG8k5UFLmGwcunTnFBdnap63lyLhUKNU1eSE/nnVq1GJmRUWKbYabJ6IwMVoWG8lDBTPmfRkZiAE9mZjIrMpI0Tb8hNZjOTpEAlGcYDIqNZVBsLHmlBIJ2eXkkWyzuix2cvlAvDg+nvstF+zPG2AzOzOS4xcL0yEgwTSJcrhLb65CXx7LkZAAmnTpFYlISiUlJ9Ct2wf2L3c685GT2HTnCD0ePMqSUC2dFnbBa2RsUVKQ7r4HTycTUVH4+epTfk5JYc/w4dxarQ+E4op45OYxKT+eHo0fZd+QIUQWPB7oiP58ZKSnsOnKEvUeOsPL4cf5fZmaRbVxgt/N/J0+y88gR9icl8eWJE3TJLTqpa7/sbBKTkrgyL48X09LYfvQoe48cYfrJk9Q5o86bjh3jIoeDjvn57p/bvIKfZWljnkpjmCaDMzNZc/w4+5OS+PnoUcafOkXtYp9VlMvFBXY7UaV8hsUlW63kViBMenIuFRqSmYkFeK+MMN4xL486LhcfFwvFH0dGEmmadM7VBLpSs6nlSeQcFAKlXhgLl7W221lX8GDha/Pz+SEkhP+XlcUTmZnUcbk4ZrEwJSqKjwoubnuDgng9KoqRGRl8EhHB5pAQAH4o+BegtsvFrJMnWRYWxuLwcLrn5PBcRga/BgfzdcG+PBFkmsQ7naQWtEDUdTpZfOIEpmHwUWQkKRYLN+Tl8eapU0S5XEwvdqF+MiMDOzCtVi1CClqeOuXm8vHJkxwvGF9zwmqlhcPBjbm5fFDw/gvtdj5PTuao1crUWrXItljokZPDhydP8qDNVmIM1svp6aQZBm9GRZHgcDA4K4tXgCEFLSovRkfzcloaWRYLUwr2ccLDVpXxaWn0y85mTkQEH0ZGkuB0cn9WFq3sdm6rWxdHwed6S24uk06d4qmYmCobX+XJuQQQ73DwWGYmw2NiygxnlxZ0520r1v27PTgYZ0H5wiqpvUj1UHgSOQftDwqiU14ejRwOEoP++2t+df7p0TUNClomartcxLpcXJWfzzV5ebwZFUWS1Uq/7GxeSUvDAXwSGUmy1cqa0FBGZmTwY0hIke61Qg1dLh6PiWFBQdnsiAg2HztG/+zsCoWnIMBW0GLTwOXiscxM6hWMswEYnZGBBbgxLs4dqGZGRjI1NZXhGRl8EhlZ5GIdapp0q1fPvcximoxPS+O41cpNcXGknxlgznho9UtpaSRarXSPiyO/4L0fR0TweXIyf09PLxGeUg2D/rGxULgf4IGsLKJcLjIsFpaHhzMqI4OTFkupP7ezuSovj3uysxkaE1NkfNGGkBA+PXmSW3Nyyhx3VBUqei4VejE9nZ1BQXxRzmDyek4nDiCl2MPB7YZBqsVC/Qq0nIn4k7rtRAJQuMvF3oJup/BSLjSzIyJwAu+lpnJlfj5NHQ4ey8iga04OcHrMCUBkwb91XC5GxsQwrVYtFoeHM6hOHfYEBfGEB91umYbBgjMumHbD4OeQEJpU8AHQ1+flsfPYMXYeO8aqEye4NSeH+eHhvBodDaZJt5wcVoWFgWliczrdX2tDQ6ltmlyaX3TY9byIiCJh6lK7naZOJ9MjI4sGJ3AHnxiXi2vy81kSHk6ky/Xf/bhcfBMWxv84nUUG0QPMiox0vx9gc0gIQUDjKnrw9a25uaQZBt+GhhY57u3BwWQaBh3POO65ERE0io+v0rv6KnouwenuuG65ubxYu3a52wyDEuOkCuUZRpFtitREankSCVAR5VxgdgcH85jNxmtpaSwqGF9zzGLhH7Vr81paGtkFF66cgvXzgSVntA6ZhsEX4eGMzMgg3uEgKejsfyqOWK1FQgRAmmFwcQVbEbYGBzMhOhoTyDEM9gYFuUNOrNNJjGkyIDubAWUMbK5bbD+HirVqNCsIM3vKuVOwmcOBBRiVkcGoMoJjrMvF0TO2nVhsP4UDnYuPR6qs5g4HtU2THWXM/VT8uKtaRc8lq2nyUloaC8LD2XZGd25pcoHgMs7fUNOs0FgsEX9SeBI5Ry0ND2dFWBiX2O1YgR3Bwe6Byb8XhKFTFgs5QLrFUuKuvZSCEBBjmiRVYH9ltbNU9DJ40mJh3RmDks9U2E60IDyceWW0qvxSLOBV5gJcuJ93IyNZW0ZX44FiYcnb465InU5YLAyz2UotT/HBXWkVOZf65ORwgcPBMzExNHY4iry/lmnS2OEg2WIh12LhuNVKEKdD8Zldd8Gmia1gzJ1ITabwJH7hcjoxi/2BNQwDa7ELk3jHbhhFWgE6FVzwCkOKaRj8EhxMG7udYNMs0pVSv6ClpvDi7M+OlBSLhQzDwAJlBqyzKQw9Le32MrfxZ8E6DsOo9H5K483P7k+rlU55eWwJCfFri8zZzqVGDgch4G6dOlPfnBz65uTwgM1WZJLVNnY7a874nW9TEM6qYx4xkaqkeC8+l5OVgd2ejyU0EjMozP2VZ3firKJxIlJSc4eDgdnZrAwNdbcWAHwRHk4Q0PeM7rBQ0+T2nBz2BAVxrODiVtg9E+2Hwbwuw+DLsDC65eTQspSJF+tU4LzZERzMn1Yrg7OySh5DQRdSitXKhpAQBmRlUa+UbVZkP6XJMYxKd+MtLvh8niylG9FqmkWOxZOpCrxR2rm0KDycB2y2El8Aq0NDecBm46eC8PVdaCiphsGgrKwi2x2UlUW2YbC6EndniviSWp7E5/LzcgkJi6BLnweJtsUBkJ6azKr50zAdmt+lqnx9/DhLwsJItFpp4nQyKCuLUxYLzxR7TMYnkZH0L7i77n8cDhKtVnrn5NDY6eS+gtvtAf4MCuKUYTAwO5tMwyDbYuGn4GAOVWA8VFV4NTqajvn5LElO5tOICH4LCiLG5eIyu51r8/K4tGHDct9vGgbP1q7NRydPsuLECeZERHDcYqGFw8GFDgf3xMYCMKZ2bT5LTmb1iRPMiojgoNVKnMvF/+bn09DppEu9eh7XfXtwMIOys3kiI4M/goJIKTZvUnk2hYYyMyKCYZmZXGK3821oKHbD4H8cDrrn5PBi7dosLRio78lUBY0cDvoUDPpuUxBIC28QOGy1uu+ahIqdS/uDg9lfWotRaioHrVaWn3EzQa5h8Hp0NK+mpTHt5Em+CQ2lXX4+vXNyeC0qilPqtpMaTuFJ/CYqpi62uPIveFJ5vwQHc2dODnWdTk5aLCwOD+eNqKgSt4fnGgb9YmN5Lj2du7KzCTdNfgkOZlCdOkXG/TgMgydtNp5NT+e1tDSCgadiYnwWnpKtVrrXrctTGRnckpvLoII5oH4LCjp9R14FrA0Lo29sLMMzM3m4YCLHP63W03fMFdgbHEy3uDiGZ2TQLzsbm8tFisXCzuBgJlXysSGToqJo7HQyJDOTKNNkQ0hIhcMTwDMxMWwPDmZAdjbPZGTg4PSA+IUREWw5y+DssjRxOksMii/8fkNISJHwVNFzyRMfR0ZiBx7OyqJLbi5JVisvRkefnqxVpIYz4uPjdU9oBXz00UcA3HfffX6tRyByOByYQWHc8eDfscU15MCe7axa8D53DH6WOvVOP4g09cQRFr7/CoYjlyAfXYwDWZhpMjMlBYCBsbG6O0lEpAzVcf3WVUokAOUaBn3r1vV3NUREzkvqWBYRERHxgMKTiIiIiAcUnkQCULjLxfajR9l+9Gipj2cREZHqozFPIgEqVqFJRMQv1PIkIiIi4gGFJxEREREPKDyJiIiIeEDhSURERMQDCk8iIiIiHtDddiIByDQMfi54CKupR7OIiPiUwpNIAMo1DLrHxfm7GiIi5yV124mIiIh4QOFJRERExAMKTyIBKMzlYtOxY2w6dowwzTQuIuJTGvMkEoAMIMHpdL8WERHfUcuTiIiIiAcUnkREREQ8oPAkIiIi4gGFJxEREREPKDyJiIiIeEB324kEIBPYExTkfi0iIr6j8CQSgHItFv5Wr56/qyEicl5St52IiIiIBxSeRERERDyg8CQSgMJcLtYcP86a48f1eBYRER/TmCeRAGQALR0O92sREfEdtTyJiIiIeEDhSURERMQDCk8iIiIiHtCYJ6kxXE4nZsE4nkKGYWC1Wv1UIxERkZIUnqRGyMnKwG7PJyQ0EtP47xDo/NxsQkEBSkREagyFJ6kR8vNyCQmLoEufB4m2xQGQnprMqvnTMB25fq5dzWMChwoCpR7PIiLiWwpPUqNExdTFFtfQ39Wo8XItFtrXr+/vaoiInJc0YFxERETEAwpPIiIiIh5QeBIJQGGmydITJ1h64gRhpkY9iYj4ksY8iQQgwzS53G53v8bQQ1pERHxFLU8iIiIiHgiY8PS3v/2Nr776ihUrVrB69Wr69u0LQGxsLJ988gnr169n9erVtGvXzv2e8spEREREKiNguu2mTJlC37592b17N40bN2bt2rV8+eWXjBkzhq1btzJgwADatGnDBx98QPv27XE4HOWWiYiIiFRGwLQ8AURHRwMQFRVFamoq+fn59OjRg5kzZwKwbds2jh49SocOHQDKLRMRERGpjIBpeRoyZAjTp08nOzub2rVr8+CDD1KrVi2CgoI4ceKEe73Dhw8THx+PzWYrs0xERESksgKi5clqtfL4448zePBg2rVrx5133slbb72l553JeS3FYiHFEhC/wiIi55SA+MvbqlUrGjRowObNm4HTXXBHjhzh4osvxul0EhcX5163cePGJCUlkZqaWmaZSKDLsVho3aABrRs0IEcBSkTEpwLir25SUhL16tWjRYsWADRr1oymTZuyf/9+lixZwsCBAwFo06YNDRo0YOPGjQDllomIiIhURkCMeUpOTmbUqFG89957mKaJYRg899xzJCUl8corrzBlyhTWr19Pfn4+jz/+uPtuuvLKRERERCojIMITwKJFi1i0aFGJ5cnJydx9992lvqe8MpFAFmaazExJAWBgbCy5mmFcRMRnAiY8ich/GaZJx/x892s9nkVExHcCYsyTiIiISE2h8CQiIiLiAXXbSY3mcjoxzxjkbxiG5vcSERG/UniSGisnKwO7PZ+Q0EjMgjE9+bnZhIIClIiI+I3Ck9RY+Xm5hIRF0KXPg0Tb4khPTWbV/GmYjlx/V01ERM5jCk9S40XF1MUW19Df1ahxsnWHnYiIXyg8iQSgHIuFvzRUoBQR8QfdbSciIiLiAYUnEREREQ8oPIkEoFDTZEZKCjNSUgg1TX9XR0TkvKIxTyIByGKadM7Lc7/W41lERHxHLU8iIiIiHlB4EhEREfGAwpOIiIiIBxSeRERERDyg8CQiIiLiAYUnEREREQ9oqgKRAJRjsdAoPt7f1RAROS+p5UlERETEAwpPIiIiIh5QeBIJQKGmybSTJ5l28qQezyIi4mMKTyIByGKa3Jqby625uacfzyIiIj6j8CQiIiLiAYUnEREREQ8oPImIiIh4QOFJRERExAMKTyIiIiIeUHgSERER8YAezyISgHIMgxYNGrhfi4iI7yg8iQQiw1BoEhHxE3XbiYiIiHhA4UkkAIWYJpNSU5mUmkqIZhgXEfEphSeRAGQ1Tfrl5NAvJwerwpOIiE8pPImIiIh4QOFJRERExAMKTyIiIiIeUHgSERER8YDCk4iIiIgHFJ5EREREPKAZxkUCUI5hcFn9+u7XIiLiOwpPElBcTiemw1FkmWEYWK1WP9XITwyDk+fbMYuI1BAKTxIwcrIysNvzCQmNxDyjtSU/N5tQOP8ClIiI+IXCkwSM/LxcQsIi6NLnQaJtcQCkpyazav40TEeun2vnWyGmyYtpaQD8s3Zt8tV1JyLiMwpPEnCiYupii2vo72r4ldU0uS87G4CXo6NB4UlExGd0t52IiIiIBxSeRERERDygbjupck6nE9M03d87HA6sVrOcd4iIiAQOhSepUk6nkzy7k+CwiDOW2jFNigQqERGRQKXwJFXKNE2CwyK4sc/DRNvqApD4xx42rVrg55qJiIhUDYUnqRbRtv/eEZd28oSfayMiIlJ1FJ5EAlCuYdCuXj33axER8R2FJ5EAZBoGh4P06ysi4g+aqkBERETEA/qvq0gACjZNRqenAzA+Ohq7uu5ERHxGLU8iASjINBmSlcWQrCyCNAWEiIhPKTyJiIiIeEDddlKm4jOFAxiGgdVq9VONRERE/E/hSUpV+kzhkJ+bTSgoQImIyHnLq/BUr149jh8/XlV1kRqktJnC01OTWTV/GqYj18+1ExER8R+vxjxt2bKFTz/9lN69exMeHl5VdZIapHCmcFtcQ3eIEhEROZ95FZ7eeOMN6tevz+TJk9m2bRtTpkzh+uuvx9Bt0yIiInKO8qrb7l//+hf/+te/aNWqFXfccQe9evXi9ttvJzk5mUWLFrFw4UK2b99eVXUVkQK5hsENcXHu1yIi4jtVMlXBrl27GDt2LFdeeSX9+/dn9erV9OvXjyVLlvD1118zbNgw4uPjvdpHSEgIL7/8MuvXr2fVqlVMmTIFgObNm7No0SLWrVvH0qVLufDCC93vKa9MJJCZhsFvwcH8FhyMqfAkIuJTVT7P0+bNm1mzZg1bt27FMAyaN2/O8OHD2bhxI9OmTaNewcNMPTVmzBhM0+Taa6/lxhtvZOzYsQCMHz+eWbNm0alTJ9555x0mTZrkfk95ZXLucDmdOByOIl9Op9Pf1RIRkXNUlYWnjh078vrrr/Pzzz/z3nvvUa9ePXdrVNu2bXn11Ve55ppr3C1GnggPD+euu+5i/Pjx7mUnTpwgNjaW1q1bs2DBAgCWLl1KfHw8zZo1K7dMzh05WRnY7flYQiMxg8LcX3l25zkdoIJNk+Hp6QxPTydYM4yLiPiUV2OeLrnkEm6//XZuu+026tevz/Hjx5k9ezbz58/n119/LbLutGnTyMvL4/nnn/d4P82aNePUqVMMGzaMTp06kZuby5tvvklaWhrHjx8vcpFMTEykUaNGpKenl1l24MCBSh+z1Cz5ebmEhEXQpc+DRNtOjwE6H6ZUCDJNRmRmAvBurVp6tp2IiA95FZ6WL19Obm4uX331FfPnz+fbb78tMSP1mX777Te2bt3q8X6sVisJCQns3buXcePG0apVK/7zn/8waNAgb6ov55ComNNTKoiIiFQ3r8LTiBEjWLJkCdnZ2RVaf8OGDWzYsMHj/SQmJuJ0Olm4cCFweoD6wYMHady4MfXq1cNqtbpbmBo1akRiYiIZGRlllomIiIhUlldjnubOnVvh4OSN1NRU1q9fz/XXXw9AQkICTZo0YcuWLezYsYPevXsD0L17d44cOcKBAwdISUkps0xERESksrwKTw888ACzZs0qs3zmzJlV1rX2zDPPMGTIEFatWsWHH37I6NGjOXr0KM888wwDBgxg3bp1DB06lOHDhxd5T1llIiIiIpXhVbdd//79+e6778os37t3L/fccw8zZszwZjcAHDx4kL59+5ZYvn//fnr27Fnqe8orExEREakMr1qemjZtyt69e8ss37dvH02bNvVmFyIiIiI1ilctT/n5+cQVPCKiNPXq1cPlcnmzCxEpRZ5h0K1uXfdrERHxHa9anrZu3Uq/fv2IjIwsURYVFcWdd95ZqakJRKR8LsNgW0gI20JCcCk8iYj4lFctT5MmTWL+/PmsWLGC6dOn89tvvwHQsmVLBg8eTL169XjssceqpKIiIiIiNYFX4emnn37ivvvuY/z48bz00kvuCTINw+DgwYPcf//9/Pjjj1VSURH5r2DT5P9lZQHwQWSkZhgXEfEhr8ITwLp167jmmmu49NJL3c+NO3DgADt27PB20yJShiDT5Pn0dAA+johQeBIR8SGvwxOAaZrs2LFDgUlERETOeVUSnv7yl7/QtGlTateujVHK/4Dnz59fFbsRERER8TuvwlPTpk3517/+xeWXX15qaILTrVIKTyIiInKu8Co8jR8/nosuuogXX3yR77//nlOnTlVRtURERERqJq/C05VXXsnbb7/Nv//976qqj4iIiEiN5tUkmampqaQX3PEjIiIicj7wKjzNnDmTO+64A4vFq82IiIfyDIM+sbH0iY3V41lERHzMq26733//HavVysqVK5kzZw5JSUk4nc4S6y1btsyb3Yh4zOV0YjocRZYZhoHVavVTjaqWyzDYGBrq72qIiJyXvApP7777rvv1888/X+o6pmnSpEkTb3Yj4pGcrAzs9nxCQiMxz2iVyc/NJhTOmQAlIiL+4VV46tu3b1XVQ6TK5OflEhIWQZc+DxJtiwMgPTWZVfOnYTpy/Vy7qhFkmtyTnQ3ArIgIHOq6ExHxGa/C06ZNm6qqHiJVLiqmLra4hv6uRrUINk1eTUsDYG54uMKTiIgPVckM4yEhIVx22WXExsayZcsWUlNTq2KzIiIiIjWO17fJPfDAA2zdupXPPvuM6dOnc8kllwBgs9nYsWMHd955p9eVFBEREakpvApP/fr145///CfffPMNTz/9dJFHtKSmpvLdd9/Rq1cvryspIiIiUlN4FZ4efvhhli9fzmOPPcbKlStLlG/fvp0LL7zQm12IiIiI1ChehadmzZrx9ddfl1l+6tQpbDabN7sQERERqVG8Ck/p6enUqVOnzPILL7yQEydOeLMLERERkRrFq/C0Zs0a7rnnHqKjo0uUXXjhhdx9992sWLHCm12ISCnyDYNBdeowqE4d8jVNgYiIT3k1VcGECRNYsmQJa9asYeXKlZimSd++fbnzzjvp1q0bx48fZ9KkSVVVVxEp4DQMVoeF+bsaIiLnJa9ano4dO0bXrl35+uuv6dGjB4Zh0Lt3b7p06cKiRYvo0aOH5nwSERGRc4rXk2SmpKQwcuRIRo4cSZ06dbBYLKSkpGCaZlXUT0RKEWSa3JGTA8BCzTAuIuJTVTLDeKGTJ09W5eZEpAzBpsmkU6cAWBwWpvAkIuJDXoWnJ598skLrTZ482ZvdiIiIiNQYXoWnESNGlFlmmiaGYWCapsKTiIiInDO8Ck8JCQkllhmGQePGjbnvvvto164dAwcO9GYXIiIiIjWK1w8GLs40TQ4dOsTYsWP5448/GDt2bFXvQkRERMRvqjw8nWnz5s387W9/q85diI+5nE4cDof7y+l0+rtKIiIiPlWld9sV17p1a1wuV3XuQnwoJysDuz2fkNBIzIK7u/JzswkFrFarfysnIiLiI16Fpz59+pS6PDo6mvbt23PLLbfw6aeferMLqUHy83IJCYugS58HibbFkZ6azKr50zAduf6u2nkn3zB4uOCh23o8i4iIb3kVnsp79MrJkyeZOnWqHs9yDoqKqYstrqG/q3FecxoGS8LD/V0NEZHzklfhqX379iWWmaZJWloaWVlZ3mxaREREpEbyKjwlJiZWVT1Eqp3L6cR0ONzfG4YRsGO1rKbJLbmnu0uXhYXhVNediIjPVOuAcTn3FQ8kDocDq7XmPdfwXBvsHmKaTCt46HaLBg3IUXgSEfEZr8LToUOHPH4AsGmaNG3a1JvdSg1RWiABO6ZJjXswtAa7i4hIVfF6wHjXrl258MILWbt2Lfv37wegRYsW/PWvf2XPnj189dVXVVJRqXmKBxKAxD/2sGnVAj/XrGwa7C4iIt7yKjwdO3aM2NhYOnfu7A5OhVq0aMHcuXM5duyYpis4x50ZSNJOnvBzbURERKqXVzOMDxkyhI8++qhEcALYt28fH330EY8++qg3uxARERGpUbwKTw0aNMBut5dZbrfbadCggTe7EBEREalRvApPe/bs4d577y01IDVs2JB7772XX3/91ZtdiIiIiNQoXo15+sc//sGnn37KunXrWLZsGQcOHACgefPmdO3aFcMwGDZsWFXUU0TOYDcMnoqJcb8WERHf8So8bdmyhVtvvZWRI0dyyy23EBYWBkBubi7ffPMNEydOVMuTSDVwGAZzIyL8XQ0RkfOS15Nk7tmzh8GDB2MYBrGxsQCkpKTUuHl+RERERKpClc0wbpomeXl5ZGVlKTiJVDOraXJ9Xh4A34SG6vEsIiI+5NWAcYDWrVvzySefsG/fPnbu3EmHDh0AsNlsfPjhh+7vRaTqhJgmM06eZMbJk4ToPysiIj7lVXi68sor+eyzz2jevDkLFizAYvnv5lJTU4mKimLAgAFeV1JERESkpvAqPI0ePZp9+/Zxww038Nprr5Uo37BhA1dccYU3uxARERGpUbwKT5dffjlz5swhPz+/1PKjR49Sr149b3YhIiIiUqN4FZ7sdnuRrrriGjRoQFZWlje7EBEREalRvApPW7dupXv37qWWhYeHc+edd7Jp0yZvdiEiIiJSo3gVniZOnEjr1q2ZMWMGN9xwAwCXXHIJ/fv356uvviI2NpbJkydXRT1FREREagSv5nn66aefGDRoEOPGjeOtt94C4IUXXgDgzz//ZODAgezevdv7WopIEXbDYEzt2u7XIiLiO16Fp1q1avHDDz/w17/+lVatWtG8eXMsFgsHDhxg+/btVVVHESnGYRh8HBnp72qIiJyXKh2eQkJC2LVrF6+99hrvvvsuu3btYteuXVVZNxEREZEap9LhKT8/nxMnTpQ5TYGIVB+LadKu4Hdvc0gILnXdiYj4jFcDxufOnUufPn0IDg6uqvqI+IzL6cThcBT5cjqd/q5WhYSaJvNTUpifkkKoHs8iIuJTXo15+vXXX7n55pv5+uuvmTt3LocOHSI3N7fEesuWLfNmNyJVLicrA7s9n5DQSMwzWm3yc7MJBaxWq/8qJyIiNZpX4Wnq1Knu1yNHjix1HdM0adKkiTe7Ealy+Xm5hIRF0KXPg0Tb4gBIT01m1fxpmI6S/wEQEREp5HF4euaZZ1i0aBG7d++mb9++1VGncvXr149JkybxwAMPsHz5cmJjY3nrrbdo1qwZeXl5jBkzhs2bNwOUWyYCEBVTF1tcQ39XQ0REAojH4Wno0KH8+uuv7N69m02bNmGz2di2bRv9+/fnu+++q446ujVu3Jh77rmHH3/80b1szJgxbN26lQEDBtCmTRs++OAD2rdvj8PhKLdMREREpDK8GjBeyPDBnT6GYfDGG2/w3HPPkZeX517eo0cPZs6cCcC2bds4evQoHTp0OGuZiIiISGVUSXjyhYceeogtW7awY8cO9zKbzUZQUBAnTpxwLzt8+DDx8fHllomIiIhUllcDxn2lZcuWdO/enTvuuMPfVRGpERyGwdjoaPdrERHxnUqFp4SEBC699FIAogv+gDdv3py0tLRS19+5c2clq3dau3btaNy4MevXrwcgLi6OCRMmMHHiRJxOJ3Fxce4WpsaNG5OUlERqamqZZSKBzm4YvFerlr+rISJyXqpUeBo5cmSJqQleffXVEusZhlElUxXMmDGDGTNmuL+fN28e06dPZ/ny5VxxxRUMHDiQN998kzZt2tCgQQM2btwIwJIlS8osExEREakMj8PT8OHDq6MelfbKK68wZcoU1q9fT35+Po8//rj7brryykQCmcU0ucxuB2BHcLAezyIi4kMeh6d58+ZVRz08cub8UsnJydx9992lrldemUggCzVNvkxOBqBFgwbkKDyJiPhMwNxtJyIiIlITKDyJiIiIeEDhSURERMQDCk8iIiIiHlB4EhEREfGAwpOIiIiIBwLi8SwiUpTDMJhYMMO4Hs8iIuJbCk8CgNPpxDRN9/cOhwOr1SznHeJPdsPgzYJHI4mIiG8pPAlOp5M8u5PgsIgzltoxTYoEKhEREVF4Ek4HpOCwCG7s8zDRtroAJP6xh02rFvi5ZlIWwzT5S8GjhvYGBWGq605ExGcUnsQt2lYXW1xDANJOnvBzbaQ8YabJ1ydOf0Z6PIuIiG/pbjsRERERDyg8iYiIiHhA4UlERETEAwpPIiIiIh7QgHGRM7icTsyCu9gKGYaB1Wr1U41ERKSmUXgSKZCTlYHdnk9IaGSRW//zc7MJBQUoEREBFJ5E3PLzcgkJi6BLnweJtsUBkJ6azKr50zAduX6uXVEOw+DdyEj3axER8R2FJ5FiomL+O99VTWU3DF6uXdvf1RAROS9pwLiIiIiIB9TyJBKADNOkkdMJQKLVqseziIj4kMKTSAAKM002Hz8O6PEsIiK+pvAkchbFpy/Q1AUiIuc3hSeRcpQ2fYGmLhAROb8pPImUo/j0BTV16gIREfEdhSeRCgiE6QtERMQ3NFWBiIiIiAcUnkREREQ8oG47kQDkNAw+iohwvxYREd9ReBIJQPmGwd9jYvxdDRGR85K67UREREQ8oJYnkUBkmtRxuQA4abGAuu5ERHxG4UkkAIWbJjuOHQP0eBYREV9Tt52IiIiIBxSeRERERDyg8CQiIiLiAYUnEREREQ8oPImIiIh4QOFJRERExAOaqkDEQy6nE9PhKLLMMAysVqvP6uA0DOaGh7tfi4iI7yg8iXggJysDuz2fkNBIzDNCS35uNqHgswCVbxg8ZbP5ZF8iIlKUwpOIB/LzcgkJi6BLnweJtsUBkJ6azKr50zAduX6unYiI+ILCk0glRMXUxRbX0H8VME3CTRPg9Ozi6roTEfEZDRgXCUDhpsm+o0fZd/SoO0SJiIhvKDyJiIiIeEDhSURERMQDCk8iIiIiHlB4EhEREfGAwpOIiIiIBxSeRERERDygeZ5EApDLMFgSFuZ+LSIivqPwJBKA8gyDh+vU8Xc1RETOS+q2ExEREfGAwpOIiIiIBxSeRAJQuMtFYlISiUlJhLtc/q6OiMh5ReFJRERExAMKTyIiIiIe0N12IlXA5XRiOhxFlhmGgdVq9VONRESkuig8iXgpJysDuz2fkNBIzDPmXMrPzSYUFKBERM4xCk8iXsrPyyUkLIIufR4k2hYHQHpqMqvmT8N05Pq5diIiUtUUnkSqSFRMXWxxDf1dDRERqWYKTyIByGUYrA4Ndb8WERHfUXgSCUB5hsGg2Fh/V0NE5LykqQpEREREPBAQ4Sk0NJQPPviAdevWsXLlSmbPnk2zZs0AiI2N5ZNPPmH9+vWsXr2adu3aud9XXpmIiIhIZQREeAKYNWsWnTp1okuXLixfvpzXX38dgDFjxrB161auvfZahg8fztSpUwkKCjprmUggC3e52HvkCHuPHNHjWUREfCwgwlNeXh5r1qxxf79161YSEhIA6NGjBzNnzgRg27ZtHD16lA4dOpy1TCTQRZgmEabp72qIiJx3AiI8FTd48GCWL1+OzWYjKCiIEydOuMsOHz5MfHx8uWUiIiIilRVw4WnYsGE0a9aMcePG+bsqIiIich4KqPD08MMPc8sttzBgwAByc3NJTU3F6XQSFxfnXqdx48YkJSWVWyYiIiJSWQETnh566CFuu+02+vfvT3p6unv5kiVLGDhwIABt2rShQYMGbNy48axlIiIiIpURELeeNWzYkBdffJEDBw4wb9484PQg8h49evDKK68wZcoU1q9fT35+Po8//jiOgqfbl1cmIiIiUhkBEZ6OHDlCo0aNSi1LTk7m7rvv9rhMpLq5nE7MM8K6YRhYrdYq2bZpGGwICXG/FhER3wmI8CQSaHKyMrDb8wkJjXSHm/zcbEKhSgJUrmHQt25dr7cjIiKeU3gSqQb5ebmEhEXQpc+DRNviSE9NZtX8aZiOXH9XTUREvKTwJFKNomLqYotr6O9qiIhIFQqYu+1E5L/CXS62Hz3K9qNH9XgWEREfU8uTiI8UH0AO3g0ij1VoEhHxC4UnER8obQA5VO0gchER8Q2FJxEfKD6AHNAgchGRAKXwJOJDxQeQV3VXnoiIVD+FJxE/UVeeiEhgUngS8RN15YmIBCaFJxE/q8xcUKZh8HNwsPu1iIj4jsKTSADKNQy6x8X5uxoiIuclTZIpIiIi4gGFJxEREREPKDyJBKAwl4tNx46x6dgxwjTTuIiIT2nMk0gAMoAEp9P9WkREfEctTyIiIiIeUHgSERER8YC67URqGD2yRUSkZlN4EqlB9MgWEZGaT+FJpAbRI1tERGo+hSeRGuhsj2wxgT1BQe7XIiLiOwpPIgEo12Lhb/Xq+bsaIiLnJd1tJyIiIuIBhScRERERDyg8iQSgMJeLNcePs+b4cT2eRUTExzTmSSQAGUDLgrmg9HgWERHfUsuTiIiIiAfU8iQSAIrPOq6OOhER/1F4EqnhSpt1PC8ny8+1EhE5fyk8idRwxWcdT09NZsPcd/1dLRGR85bCk0iAONus4yIi4hsKTyIByAQOWiwYhqHHs4iI+JjCk0gAyrFYuKpuXYKC9CssIuJrmqpARERExAMKTyIiIiIeUJu/SAAKcThYnJIChsFtNhu5hoFhGFitVn9XTUTknKfwJBJgcrIycNrzucLpBMCwhmJaLOTnZhMKClAiItVM3XYiASY/L5eQ0HD39z3vH8WNfR4mOCwC09S9dyIi1U0tTyIBLqZuA/JDQv1dDRGR84ZankREREQ8oJYnkXNE8YcHAxpELiJSDRSeRM4BpT08GNAgchGRaqDwJBKgMiJqYVhO97wXf3gwQHpqMqvmT8N05PqzmiIi5xyFJ5EAlG2x8PTTb1CnXnyR5Xp4sIhI9VN4EjmHFR8HpTFQIiLeU3gSOUeVNg5KY6BERLyn8CQSgMJMF8M/nkhwcCj/fvTFUtcpPg5KY6BERKqGwpNIALKY0PLPvQAYZ5lVXOOgRESqlibJFBEREfGAwpOIiIiIBxSeRERERDygMU8i5zmn04lZbNyUpjQQESmbwpPIeaT4vE8ulwu70yQkPLLIeprSQESkbApPIgEqLzgE44zn2J1NafM+uRx2goOCuLHPQ3qsi4hIBSk8iQSgbIuFx5+dUuLxLOUp7fl3iX/sYdOqBZrOQETEAwpPIueZM4NS2skTfq6NiEjg0d12IiIiIh5Qy5NIAAo1TR779G2CQ8OYNfiZKt++HigsIlI2hSeRAGQ1TS7btxMAw+Wq0m2XNrA8NzuTYKujSIAyTbPEgPWKhKyqnBpB0yyIiD8oPIlIEcUHlh9P/JPVC9/HCAn77116Tif5+bmEhUfAGQHqbFMcOJ1O8uxOgsMiiiwvLZydLQSVtS1NsyAi1U3hSURKVTiwPO3kiTLv0rvxjGXpqcmsmPMOdnuOuzWoeOuUw+EgODSSG/s8TLStLkCp4QzOHoJM0yQ4LKLItjTNgoj4gsKTiFRIaXfpnbmseHdf6a1TdkwTomJii2yreDjzJARF2zyfZkFdhyLijXM+PDVv3pzJkydTp04d0tPTeeqpp/jtt9/8XS2Rc07x7r7SWqcKl5Wm+FxTxQetl9aKZbUWDS2lKR5uqnJWdXUdipyfzvnwNH78eGbNmsXcuXPp3r07kyZNonv37v6ull8Vv5hU9CIkUhFndved+T1UfF4pT1qxirf6nBm6SgtKZc2qfrYuRyjZolRW12HxbVW0Jar476ZasERqJiM+Pv6cvWrGxsby3Xff0apVK5xOJwA//fQTt99+OwcOHPBoW1988QVWq5UTJ6pnUsHiF4BqZ5wxxZdpggHhkdFYLKf/UDsddnJzsgiPjCpzWUXWqQnvqwl1qOq65+dkklBwTqfExOJwOGpc3avimMPCIzEsltPHnJfr/r5wnfy83KLvczrIyUovCD2G+9wOC6/l2fswzwhP/w1QpumixANxDMtZtlXG+8pyxu+mR+8TCXCePG7KE3FxcTidTnr27Fll2zynW57i4+M5fvy4OzgBJCYm0qhRI4/Dk91ur+LaFVVdJ03ZzghrBbvOzUovsoZRgWUVWacmvK8m1KEq6w5wsLBFIuNUja27t8ecl5NZ5vdlvc/i/l0y3ee2x+/jzN/Joi1BJZkebKsizrY/EfGE0+ms8mv4OR2eqlLv3r39XQURERGpAc7px7MkJSVRr169ImMGGjVqRGJioh9rJSIiIoHsnA5PKSkp7Nixw91q1L17d44cOeJxl52IiIhIoXN6wDjABRdcwKRJk7DZbGRkZDB8+HB+/fVXf1dLREREAtQ5H55EREREqtI53W0nIiIiUtUUnkREREQ8oPAkIiIi4gGFJxEREREPKDyJiIiIeEDhSURERMQDCk8iIiIiHlB4EhEREfGAwpOfNW/enEWLFrFu3TqWLl3KhRde6O8qVdrf/vY3vvrqK1asWMHq1avp27cvALGxsXzyySesX7+e1atX065dO/d7yiurSV566SU2bdpEYmIirVq1ci8PCQnh5ZdfZv369axatYopU6a4y8r7bGvq5x4aGsoHH3zAunXrWLlyJbNnz6ZZs2ZF1rnmmms4ePAggwcPdi8LCwtj6tSprF+/nnXr1tG9e/cKlfnbp59+ysqVK1mxYgULFy6kVatWZ/0ZBPL53K9fPxITE7n55puByh9LTT9OKHmsl19+OYsXL2b58uV88803DBkyxL1uoJ6/mzZt4ttvv2XFihWsWLGCnj17Aufe3yUo/5ig5OcN1XsOB3l3OOKt8ePHM2vWLObOnUv37t2ZNGlSjfrl9MSUKVPo27cvu3fvpnHjxqxdu5Yvv/ySMWPGsHXrVgYMGECbNm344IMPaN++PQ6Ho9yymmTp0qW8++67fPbZZ0WWjxkzBtM0ufbaawGIi4tzl5X32dbkz33WrFmsWbMGgPvuu4/XX3/dHYSjoqJ49tln3eWFHnnkEfLz87n22mtJSEhgyZIlbNiwgdTU1HLL/O2RRx4hPT0dgK5duzJ58mRuvfXWcn8GgXo+N27cmHvuuYcff/zRvayyx1KTjxNKP9YJEybw+uuvs3LlSmJiYli7di2rVq1i7969AXv+AgwZMoRdu3YVWXYu/l0q75hK+7wL31Nd57BanvwoNjaW1q1bs2DBAuD0BTo+Pr7E//QDSXR0NHD6Ipuamkp+fj49evRg5syZAGzbto2jR4/SoUMHgHLLapLNmzdz5MiRIsvCw8O56667GD9+vHvZiRMngPI/25r8uefl5RUJRlu3biUhIcH9/SuvvMJbb71V4sLRs2dP9+d46NAhNm7cSNeuXc9a5m+FwQlOn7umaZ71ZxCI57NhGLzxxhs899xz5OXluZdX9lhq6nFC2cdqmia1a9cGICIiArvdzqlTp4DAPX9Lcy7+XSrvmMr6vKF6z2G1PPlRfHw8x48fx+l0upclJibSqFEjDhw44L+KVdKQIUOYPn062dnZ1K5dmwcffJBatWoRFBTkPtEBDh8+THx8PDabrcyyQNCsWTNOnTrFsGHD6NSpE7m5ubz55pusX7++3M82PT09YD73wYMHs3z5cgC6d++Oy+Vi5cqVdOvWrch6jRo14vDhw+7vDx06RKNGjc5aVhO89dZbdOzYEYCBAweWKD/zZ1DeOVuTz+eHHnqILVu2sGPHDveyyh5LTT5OKP1YAYYPH86HH37IqFGjqFOnDs8884z7GAL5/J08eTKGYfDzzz/z6quvUr9+/XPu71J5f2vL+ryr+xxWeJIqYbVaefzxxxk8eDCbN2+mTZs2/Pvf/+amm27yd9WqjdVqJSEhgb179zJu3DhatWrFf/7zH2644QZ/V61KDBs2jGbNmjFq1Cji4uJ44okn6NOnj7+rVeWeeOIJAPr27cuYMWMYNGiQu+zMn0GgatmyJd27d+eOO+7wd1WqXXnHOnToUMaNG8fnn39OkyZNWLBgAdu2bWPv3r1+qGnVuOOOO0hKSiIoKIhRo0YxefJkJkyYcM79XSrrb+2DDz7ot3Nb3XZ+lJSURL169bBare5ljRo1IjEx0Y+1qpxWrVrRoEEDNm/eDJxuBj1y5AgXX3wxTqezRP90UlISqampZZYFgsTERJxOJwsXLgRg165dHDx4kIsvvrjczzYQPveHH36YW265hQEDBpCbm0vr1q2pV68eK1asYNOmTXTv3p0nn3yS0aNHA6d/Fo0bN3a/PyEhwX085ZXVJPPmzaNjx47YbDag5M8AKPecrannc7t27WjcuDHr169n06ZNtG3blgkTJtCjR49KHUtNPU4o+1iffPJJunbtyueffw7AwYMH2bp1K1dddRUQuOdv4c/c4XAwffp02rVrd07+XSrvmEr7vAcNGlTt57DCkx+lpKSwY8cOevfuDZzuFjly5Ijfm0gro/AXr0WLFsDpZtamTZuyf/9+lixZ4u4OadOmDQ0aNGDjxo0A5ZbVdKmpqaxfv57rr78eOP1HtUmTJuzdu7fcz7amf+4PPfQQt912G/3793ePCVq9ejWXX3457du3p3379ixdupTJkye7xyCc+TkmJCTQoUMHvvrqq7OW+VN0dDT169d3f3/zzTdz6tQpUlNTS/0ZFAq083nGjBm0bdvW/dlt3bqVUaNGMWPGjEofS008Tij7WKdMmUJ2djbXXHMNcLpL54orrmDPnj1AYJ6/4eHh7jGmALfddhs7d+48J/8ulXVMy5YtK/Pchuo9h434+HizCo9RPHTBBRcwadIkbDYbGRkZDB8+nF9//dXf1aqUXr16MWzYMEzTxDAM3n77bT7//HPq1q3LlClTaNKkCfn5+Tz33HNs2LABoNyymmT8+PF07tyZuLg4UlNTyczM5Nprr6VJkyZMnDgRm82GaZpMmjSJL7/8Eij/s62pn3vDhg354YcfOHDgAFlZWcDpQeQ9evQost6kSZPYtWsX06dPB07/IX/zzTdp3bo1LpeLCRMmsHjx4rOW+VOjRo2YNm0aYWFhmKZJSkoKY8eO5eTJk+X+DAL9fJ43bx7Tp09n+fLllT6WQDhOKHqsnTp1YsyYMQQFBREUFMTs2bP5v//7PyAwz98mTZrw/vvvY7FYMAyDgwcP8sILL3D48OFz7u8SUO4xFTrz84bqPYcVnkREREQ8oG47EREREQ8oPImIiIh4QOFJRERExAMKTyIiIiIeUHgSERER8YDCk4iIiIgHFJ5EREREPKDwJCJSw82bN4/Vq1f7uxoiUkDhSUSqRGJiYoW+OnToUCX7q1+/PsOHD6dVq1YVWr9fv34kJibSunXrKtl/VfP0eETEf4L8XQEROTcMGzasyPd9+vThuuuuK7G8qp5iX79+fUaMGMHhw4fZtWtXlWzTn8614xE5lyk8iUiVKHzieaG2bdty3XXXlVguIhLo1G0nIj5jGAaDBw9mzZo17N+/n59//pnx48dTu3Zt9zojRozg0KFDXHvttUXeO378eP744w8uueQSOnTowLJly4DTDyku7BLs16+f13Vs0KABEydO5Oeff+b3339nzZo13HnnnUXW6dChA4mJifTo0YPHH3+cH374gf379zNnzhyaNWtWYpv33nsvGzZsYN++fSxZsoSrr76aefPmMW/ePPf2KnI8f/nLX5g3bx779u3jhx9+YMiQIV4fr4h4Ti1PIuIz48ePp1+/fsyZM4cPP/yQhIQE7r//flq1asVtt92Gw+HgrbfeokuXLrzxxht07tyZrKwsrrvuOgYMGMCECRP45ZdfqFu3Lq+//jojR47kk08+YfPmzQD88MMPXtWvbt26LF68GNM0+eijj0hJSeGGG27gzTffJCoqiunTpxdZf+jQobhcLt577z2ioqJ49NFH+de//kWPHj3c6wwaNIhXX32VTZs28f7775OQkMCHH37IqVOnOHLkCHC6K/Nsx1O7dm1mzZrFsmXLWLx4Md27d+e5557j119/5euvv/bquEXEMwpPIuITV111Fffccw9Dhw7l888/dy/fsGEDn376Kbfeeiuff/45DoeDJ554gmXLlvHiiy/y8ssvu1uC3n77bQCSk5NZs2YNI0eO5Mcff6yyrsHRo0djsVi48cYbSU1NBWDmzJlMnTqV4cOH88knn5Cbm+tePzQ0lJtuugm73Q5AWloaY8eOpWXLluzZs4fg4GBGjhzJTz/9RL9+/XA6nQDs3r2byZMnu8NTRY6nYcOGPP744yxYsACA2bNns3nzZvr376/wJOJj6rYTEZ+49dZbSUtL49tvv8Vms7m/tm/fTmZmJh07dnSvu2fPHiZOnMg999zDrFmzsNlsPPnkk+7wUV26devGqlWrAIrUce3atdSuXZtLL720yPpz5sxxByfA3WLUpEkTANq0aUOdOnX49NNPi9R94cKF7nBWUZmZme7gBGC32/n555/d+xIR31HLk4j4RPPmzalduzY7duwotbxu3bpFvn/33Xfp1asXbdu2Zdy4cVV2l15ZYmNjiYmJYcCAAQwYMKBCdUxKSiryfVpaGgAxMTEANGrUCIADBw4UWc/pdHL48GGP6lfYSlV8fxdffLFH2xER7yk8iYhPWCwWTpw4UWLqgkIpKSlFvm/atCnNmzcH4KKLLvJJ/QAWLFjgHshd3C+//FLk+7JawgzDqNrK+XhfIlI+hScR8Yk///yTTp06sWXLliLjhkpjGAaTJk0iIyOD6dOn8/jjj7N06VL3HWkApmlWaf1SUlLIyMjAYrGwbt26KtlmYmIiAM2aNWPDhg3u5VarlcaNG7N79273sqo+HhGpPhrzJCI+sXjxYoKCgnjyySdLlFmtVqKjo93fP/TQQ1x11VWMHj2aCRMmsGXLFsaNG4fNZnOvk52dDVDkfd5wuVx8+eWXdOvWjZYtW5Yor1Onjsfb3LZtGydPnuTuu+/GarW6l99xxx1FjgWq/nhEpPqo5UlEfGLTpk3MnDmTYcOGcckll/Dtt99it9v5n//5H7p3786LL77I0qVLadGiBSNHjmTOnDmsXLkSgKeeeooVK1Ywbtw4HnnkEeB0S9apU6cYOHAgmZmZZGdn89NPP3Ho0KFy63HXXXdxww03lFg+ffp0Xn31VTp27MiSJUv49NNP+e2334iJieGyyy7j2muvLTFg/GzsdjsTJ07klVdeYe7cuSxevJiEhAT69evHH3/8UWTdyh6PiPiewpOI+MwzzzzD9u3bGTBgAM888wwOh4NDhw6xcOFCtmzZgsViYfLkyaSmpvLiiy+63/fHH38wbtw4xo4dy9KlS1m8eDEOh4Mnn3ySZ599ltdee43g4GCeeuqps4aNe++9t9Tlc+fO5ciRI3Tv3p2nnnqKW265hUGDBpGamspvv/3Gq6++Wqlj/uijjzAMg4cffpjnn3+eX375hfvvv5+XXnqpSPdlZY9HRHzPiI+PV0e7iIgPGYbBjh07+PLLLxk1apS/qyMiHtKYJxGRahQaGlpiWd++fbHZbGzcuNEPNRIRb6nbTkSkGrVt25Z//OMfLFmyhNTUVC677DLuuusudu/ezZIlS/xdPRGpBIUnEZFqdOjQIZKSknjggQeIiYnh1KlTzJ8/n1dffbXI7OQiEjg05klERETEAxrzJCIiIuIBhScRERERDyg8iYiIiHhA4UlERETEAwpPIiIiIh5QeBIRERHxgMKTiIiIiAcUnkREREQ88P8BWQVUmgt/Lf4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#this just measures space-delimited words which isn't necessarily the same as toke count, but it should be close-ish\n",
    "plot_text_length_histogram(train_df, percentile = 96)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0851b1bc-71dd-4c6b-94ff-2193c98c4e4b",
   "metadata": {},
   "source": [
    "## Load source model/tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3d05cc5-123a-4e12-82cd-57671df3a049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b0382bbbddf43b1990068aa9820444b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/venv/lib/python3.10/site-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.93 s, sys: 31.7 s, total: 37.6 s\n",
      "Wall time: 3min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "# Quantization config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=\"float16\",\n",
    ")\n",
    "\n",
    "# loading the model with quantization config\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    source_hf_model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    token = hf_token,\n",
    ")\n",
    "\n",
    "model.config.use_cache = True  #surpress the download and use cache. # apparently needed because of https://github.com/huggingface/transformers/pull/24906\n",
    "model.config.pretraining_tp = 1  #disable tensor parallelism\n",
    "#print(model)\n",
    "\n",
    "#fixme\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    source_hf_model_name, \n",
    "    trust_remote_code=True, \n",
    "    return_token_type_ids=False,\n",
    "    token = hf_token,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40757681-3f73-4b95-9e14-9228c67b668c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abcc7db5c2d0449280f297487ab799b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11214 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d03fe8c25c4021aa64d47ef7843e45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1246 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.4 s, sys: 1.77 s, total: 30.2 s\n",
      "Wall time: 21.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import trl\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from peft import prepare_model_for_kbit_training\n",
    "from trl import SFTTrainer\n",
    "from transformers import EarlyStoppingCallback\n",
    "import transformers\n",
    "\n",
    "\n",
    "\n",
    "# Parameter efficient finetuning for LoRA configuration\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    #target_modules=[ \"q_proj\",\"v_proj\",],  # we will only create adopters for q, v metrices of attention module\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\"],\n",
    "    r=lora_r,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "\n",
    "training_arguments = transformers.TrainingArguments(\n",
    "    output_dir=project_dir,\n",
    "    #load_from_checkpoint=str,\n",
    "    seed = seed,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    learning_rate= learning_rate,\n",
    "    #lr_scheduler_type=\"linear\",\n",
    "    save_strategy=\"steps\",\n",
    "    logging_steps=logging_steps,\n",
    "    num_train_epochs=epochs,\n",
    "    max_steps=0,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    "    evaluation_strategy=\"steps\",  # Add this line\n",
    "    eval_steps=logging_steps,  # Add this line\n",
    "    metric_for_best_model=\"loss\",\n",
    "    greater_is_better=False,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    peft_config=peft_config,  # passing peft config\n",
    "    dataset_text_field=\"text\",  # mentioned the required column\n",
    "    args=training_arguments,  # training agruments\n",
    "    tokenizer=tokenizer,  # tokenizer\n",
    "    packing=False,\n",
    "    max_seq_length=max_training_sample_length,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=early_stopping_patience)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d1ced4-7675-4be0-957c-a7e232ec7af9",
   "metadata": {},
   "source": [
    "## Train lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9bfc5b-da5b-4f93-9b5b-e9e48097f947",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='524' max='700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [524/700 5:37:01 < 1:53:37, 0.03 it/s, Epoch 1.49/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.209800</td>\n",
       "      <td>1.187238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.138500</td>\n",
       "      <td>1.176472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.110000</td>\n",
       "      <td>1.170948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.124200</td>\n",
       "      <td>1.163659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.098700</td>\n",
       "      <td>1.159371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.099800</td>\n",
       "      <td>1.155005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.107700</td>\n",
       "      <td>1.150710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.070700</td>\n",
       "      <td>1.145581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>1.077100</td>\n",
       "      <td>1.140861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.078300</td>\n",
       "      <td>1.136599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>1.075900</td>\n",
       "      <td>1.131553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.063300</td>\n",
       "      <td>1.126130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>1.060200</td>\n",
       "      <td>1.121462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.083400</td>\n",
       "      <td>1.117483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>0.958200</td>\n",
       "      <td>1.121343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.944700</td>\n",
       "      <td>1.116060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>0.916000</td>\n",
       "      <td>1.117001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.936300</td>\n",
       "      <td>1.106538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>0.914200</td>\n",
       "      <td>1.102938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.897700</td>\n",
       "      <td>1.096904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "if False:\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f12d4322-25cf-4a33-92a2-a23eab8439b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">done!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "done!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fae22eb-210a-4f8b-97f2-fa9fda59a0b7",
   "metadata": {},
   "source": [
    "## save peft model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c40dedb5-c6af-47b8-936f-fbf5b16cec9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:4\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "trainer.model.save_pretrained(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04d58d58-3ba8-44e8-b6fc-a51154a9af8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chat_summarizer'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13c0d830-d825-41f4-91b6-d7e424844dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 375M\n",
      "   0 drwxr-xr-x 1 root root 4.0K Nov  5 12:28 .\n",
      "   0 drwxr-xr-x 1 root root 4.0K Nov  5 17:35 ..\n",
      "4.0K -rw-r--r-- 1 root root 1.3K Nov  5 18:26 README.md\n",
      "375M -rw-r--r-- 1 root root 375M Nov  5 18:26 adapter_model.bin\n",
      "   0 -rw-r--r-- 1 root root  493 Nov  5 18:26 adapter_config.json\n"
     ]
    }
   ],
   "source": [
    "!ls -lhatrs ./$project_path/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfc7faf6-3e0c-4f5c-922d-cabd545bac5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 375M\n",
      "   0 drwxr-xr-x 1 root root 4.0K Nov  5 12:28 .\n",
      "   0 drwxr-xr-x 1 root root 4.0K Nov  5 17:35 ..\n",
      "4.0K -rw-r--r-- 1 root root 1.3K Nov  5 18:26 README.md\n",
      "375M -rw-r--r-- 1 root root 375M Nov  5 18:26 adapter_model.bin\n",
      "   0 -rw-r--r-- 1 root root  493 Nov  5 18:26 adapter_config.json\n"
     ]
    }
   ],
   "source": [
    "!ls -latrsh ./$project_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "787bccd7-4a58-4cfa-a3fc-3a30d0a9b122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "library_name: peft\n",
      "---\n",
      "## Training procedure\n",
      "\n",
      "\n",
      "The following `bitsandbytes` quantization config was used during training:\n",
      "- quant_method: bitsandbytes\n",
      "- load_in_8bit: False\n",
      "- load_in_4bit: True\n",
      "- llm_int8_threshold: 6.0\n",
      "- llm_int8_skip_modules: None\n",
      "- llm_int8_enable_fp32_cpu_offload: False\n",
      "- llm_int8_has_fp16_weight: False\n",
      "- bnb_4bit_quant_type: nf4\n",
      "- bnb_4bit_use_double_quant: False\n",
      "- bnb_4bit_compute_dtype: float16\n",
      "\n",
      "The following `bitsandbytes` quantization config was used during training:\n",
      "- quant_method: bitsandbytes\n",
      "- load_in_8bit: False\n",
      "- load_in_4bit: True\n",
      "- llm_int8_threshold: 6.0\n",
      "- llm_int8_skip_modules: None\n",
      "- llm_int8_enable_fp32_cpu_offload: False\n",
      "- llm_int8_has_fp16_weight: False\n",
      "- bnb_4bit_quant_type: nf4\n",
      "- bnb_4bit_use_double_quant: False\n",
      "- bnb_4bit_compute_dtype: float16\n",
      "\n",
      "The following `bitsandbytes` quantization config was used during training:\n",
      "- quant_method: bitsandbytes\n",
      "- load_in_8bit: False\n",
      "- load_in_4bit: True\n",
      "- llm_int8_threshold: 6.0\n",
      "- llm_int8_skip_modules: None\n",
      "- llm_int8_enable_fp32_cpu_offload: False\n",
      "- llm_int8_has_fp16_weight: False\n",
      "- bnb_4bit_quant_type: nf4\n",
      "- bnb_4bit_use_double_quant: False\n",
      "- bnb_4bit_compute_dtype: float16\n",
      "### Framework versions\n",
      "\n",
      "- PEFT 0.5.0\n",
      "- PEFT 0.5.0\n",
      "\n",
      "- PEFT 0.5.0\n"
     ]
    }
   ],
   "source": [
    "!cat ./$project_path/README.md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cce7d8-03a6-4bd5-91b4-f9c8918726dd",
   "metadata": {},
   "source": [
    "## Load peft model from checkpoint on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f030a0e-f519-42bc-b1fb-8c11b2bd59d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpeft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoraConfig, get_peft_model\n\u001b[1;32m      2\u001b[0m lora_config \u001b[38;5;241m=\u001b[39m LoraConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(project_path)\n\u001b[0;32m----> 3\u001b[0m lmodel \u001b[38;5;241m=\u001b[39m get_peft_model(\u001b[43mmodel\u001b[49m, lora_config)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "lora_config = LoraConfig.from_pretrained(project_path)\n",
    "lmodel = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e869dacf-b6b2-4ad1-942d-b5336e4606c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">### Instruction: \n",
       "Write a concise summary of the below input text.Ensure that responses covers the key points of the text.Only \n",
       "provide full sentence responses.\n",
       "### Input: \n",
       "#Person1#: Well, Charles, I must say that your shop is pretty remarkable. Do people send the fax messages abroad, \n",
       "or is it just to this country?\n",
       "#Person2#: It's surprising because when I started, I thought I'd be sending things to London and maybe Birmingham \n",
       "but, in fact, a high percentage of it is sent abroad, because it's immediate and speedy.\n",
       "#Person1#: And how much would it cost, for example, if I wanted to send a fax to the United States?\n",
       "#Person2#: Well, a fax to the United States would cost you five pounds for a page. And when you think that in \n",
       "England by the Royal Mail, it would cost you twelve pounds to send a page by special delivery, it's actually a good\n",
       "value.\n",
       "#Person1#: Ok. What about your hours? How long do you have to spend actually in the shop?\n",
       "#Person2#: Well, the shop is open from eight in the morning until six at night, six days a week, and then a sort of\n",
       "fairly flexible morning on a Sunday. Urn, and of those hours, I'm in it quite a lot.\n",
       "#Person1#: And did you enjoy it?\n",
       "#Person2#: Yes, overall I enjoy it. Running a business by yourself is hard work and you never quite like every \n",
       "aspect all the time. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">95</span>% of the customers I love. Uh, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>% I really, you know, I'm not too bothered about. And <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>% I \n",
       "positively hate.\n",
       "#Person1#: What, what's the problem with those?\n",
       "#Person2#: Um, it's hard to categorize really. I find people who are just totally rude, um, unnecessary, and I \n",
       "don't really need their business and I suppose they form the volume of the people that I don't like but it's a very\n",
       "small percentage.\n",
       "### Response :\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "### Instruction: \n",
       "Write a concise summary of the below input text.Ensure that responses covers the key points of the text.Only \n",
       "provide full sentence responses.\n",
       "### Input: \n",
       "#Person1#: Well, Charles, I must say that your shop is pretty remarkable. Do people send the fax messages abroad, \n",
       "or is it just to this country?\n",
       "#Person2#: It's surprising because when I started, I thought I'd be sending things to London and maybe Birmingham \n",
       "but, in fact, a high percentage of it is sent abroad, because it's immediate and speedy.\n",
       "#Person1#: And how much would it cost, for example, if I wanted to send a fax to the United States?\n",
       "#Person2#: Well, a fax to the United States would cost you five pounds for a page. And when you think that in \n",
       "England by the Royal Mail, it would cost you twelve pounds to send a page by special delivery, it's actually a good\n",
       "value.\n",
       "#Person1#: Ok. What about your hours? How long do you have to spend actually in the shop?\n",
       "#Person2#: Well, the shop is open from eight in the morning until six at night, six days a week, and then a sort of\n",
       "fairly flexible morning on a Sunday. Urn, and of those hours, I'm in it quite a lot.\n",
       "#Person1#: And did you enjoy it?\n",
       "#Person2#: Yes, overall I enjoy it. Running a business by yourself is hard work and you never quite like every \n",
       "aspect all the time. \u001b[1;36m95\u001b[0m% of the customers I love. Uh, \u001b[1;36m2\u001b[0m% I really, you know, I'm not too bothered about. And \u001b[1;36m3\u001b[0m% I \n",
       "positively hate.\n",
       "#Person1#: What, what's the problem with those?\n",
       "#Person2#: Um, it's hard to categorize really. I find people who are just totally rude, um, unnecessary, and I \n",
       "don't really need their business and I suppose they form the volume of the people that I don't like but it's a very\n",
       "small percentage.\n",
       "### Response :\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The above conversation between two persons named Person1 and Person2 took place in an office where both were working as employees. The first person was interested in knowing more details regarding the services provided by his colleague’s company which he had heard recently. He asked him whether there were any other countries apart from UK whose citizens\n"
     ]
    }
   ],
   "source": [
    "#text = test_df['text'][500]\n",
    "print(text)\n",
    "result = generate(text, lmodel, max_new_tokens=64, temp=0.1)\n",
    "#del lmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cf2bb12c-2f64-44b6-94a5-c52e82ba7412",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "974716d4-a8d1-4ea0-a43a-64d2a063f172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The above conversation between two persons named Person1 and Person2 took place in an office where both were working as employees. The first person was interested in knowing more details regarding the services provided by his colleague’s company which he had heard recently. He asked him whether there were any other countries apart from UK whose citizens'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1628a103-d702-4bea-b56d-f7d7f29b74a7",
   "metadata": {},
   "source": [
    "## load the orignal mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f68debd1-1547-4210-b56c-4bf51ce35621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chat_summarizer/best_checkpoint'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3bcd0ff-edd5-42c7-8b7f-63e91fea44c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c43707b08a09480dbcfe877a5c0fa367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/venv/lib/python3.10/site-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.8 s, sys: 27.9 s, total: 1min 14s\n",
      "Wall time: 5min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import  AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\n",
    "#     source_hf_model_name, \n",
    "#     trust_remote_code=True, \n",
    "#     return_token_type_ids=False,\n",
    "#     token = hf_token,\n",
    "# )\n",
    "tokenizer = AutoTokenizer.from_pretrained(source_hf_model_name)\n",
    "persisted_model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    project_path,\n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device,\n",
    "    token=hf_token,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5d2a7b5-7e32-443e-8eee-01a45e50c125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">### Instruction: \n",
       "Write a concise summary of the below input text.Ensure that responses covers the key points of the text.Only \n",
       "provide full sentence responses.\n",
       "### Input: \n",
       "#Person1#: Mister Ewing said we should show up at the conference center at <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">4:00</span> o'clock, right?\n",
       "#Person2#: Yes, he especially asked us not to be late. Some of the people from our east york branch office are \n",
       "coming, and he wants to make a good impression on them. How are you getting there?\n",
       "#Person1#: I was thinking of taking my car, but I think I'm just going to take the underground, because there is \n",
       "construction on the highway. What about you?\n",
       "#Person2#: I'll be taking the underground as well. Why don't we go together? I've been to the conference center \n",
       "only once, and I'm not sure if I can find my way around there.\n",
       "### Response :\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "### Instruction: \n",
       "Write a concise summary of the below input text.Ensure that responses covers the key points of the text.Only \n",
       "provide full sentence responses.\n",
       "### Input: \n",
       "#Person1#: Mister Ewing said we should show up at the conference center at \u001b[1;92m4:00\u001b[0m o'clock, right?\n",
       "#Person2#: Yes, he especially asked us not to be late. Some of the people from our east york branch office are \n",
       "coming, and he wants to make a good impression on them. How are you getting there?\n",
       "#Person1#: I was thinking of taking my car, but I think I'm just going to take the underground, because there is \n",
       "construction on the highway. What about you?\n",
       "#Person2#: I'll be taking the underground as well. Why don't we go together? I've been to the conference center \n",
       "only once, and I'm not sure if I can find my way around there.\n",
       "### Response :\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The meeting will start at four in the afternoon according to Mr. Ewing who has requested for everyone to arrive early so they do not miss out anything important during the event. He also mentioned that some members from their East York Branch Office would attend this meeting which means it’s very crucial since these individuals have never\n"
     ]
    }
   ],
   "source": [
    "#text = test_df['text'][500]\n",
    "print(text)\n",
    "result = generate(text, persisted_model, max_new_tokens=64, temp=0.1)\n",
    "#del persisted_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c5eca4a-dbf3-463c-97e1-b2df66da15ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Driving is no longer considered as one of the best ways for travelers who want to explore China in depth because there are many other options available nowadays such as taking trains or planes which can save both money & time compared with cars especially when going from Beijing (the capital city) all over'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "788fd3c3-140e-4f8d-8594-dfd01c8d6acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "del persisted_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1af269a-c9c8-4a7b-898b-16ded1a5d4f5",
   "metadata": {},
   "source": [
    "## Merge the lora and original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59d50514-acd2-48a5-abc3-ec86c29673de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 13G\n",
      "   0 -rw-r--r-- 1 root root   42 Nov  5 15:59 added_tokens.json\n",
      "   0 drwxr-xr-x 1 root root 4.0K Nov  5 15:59 .\n",
      "4.0K -rw-r--r-- 1 root root  656 Nov  5 21:28 config.json\n",
      "   0 -rw-r--r-- 1 root root  183 Nov  5 21:28 generation_config.json\n",
      "9.3G -rw-r--r-- 1 root root 9.3G Nov  5 21:35 model-00001-of-00002.safetensors\n",
      "3.3G -rw-r--r-- 1 root root 3.3G Nov  5 21:35 model-00002-of-00002.safetensors\n",
      " 24K -rw-r--r-- 1 root root  24K Nov  5 21:35 model.safetensors.index.json\n",
      "4.0K -rw-r--r-- 1 root root  900 Nov  5 21:35 tokenizer_config.json\n",
      "   0 -rw-r--r-- 1 root root  414 Nov  5 21:35 special_tokens_map.json\n",
      "492K -rw-r--r-- 1 root root 489K Nov  5 21:35 tokenizer.model\n",
      "1.8M -rw-r--r-- 1 root root 1.8M Nov  5 21:35 tokenizer.json\n",
      "   0 drwxr-xr-x 1 root root 4.0K Nov  6 06:33 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "merged_dir\n",
    "!ls -lathrs $merged_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "251ae65f-46f8-45d6-94da-61edc884dccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unloading and merging model: 100%|██████████| 454/454 [00:18<00:00, 25.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 51s, sys: 5.47 s, total: 6min 57s\n",
      "Wall time: 7min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "merged_model = persisted_model.merge_and_unload(progressbar=True)\n",
    "\n",
    "merged_model.save_pretrained(merged_dir, safe_serialization=True)\n",
    "tokenizer.save_pretrained(merged_dir)\n",
    "\n",
    "del persisted_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c3c607-e405-4d95-bad2-102931f38686",
   "metadata": {},
   "source": [
    "## Load merged model from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e278c014-3120-443d-9713-405b44f4003c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25267265926e439ba07d819c71f99217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.3 s, sys: 2min 39s, total: 2min 59s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = AutoTokenizer.from_pretrained(merged_dir)\n",
    "merged_model_from_disk = AutoModelForCausalLM.from_pretrained( merged_dir, device_map=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51f0bcf5-3eb4-4858-9f27-634daeb486a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">### Instruction: \n",
       "Write a concise summary of the below input text.Ensure that responses covers the key points of the text.Only \n",
       "provide full sentence responses.\n",
       "### Input: \n",
       "#Person1#: Mister Ewing said we should show up at the conference center at <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">4:00</span> o'clock, right?\n",
       "#Person2#: Yes, he especially asked us not to be late. Some of the people from our east york branch office are \n",
       "coming, and he wants to make a good impression on them. How are you getting there?\n",
       "#Person1#: I was thinking of taking my car, but I think I'm just going to take the underground, because there is \n",
       "construction on the highway. What about you?\n",
       "#Person2#: I'll be taking the underground as well. Why don't we go together? I've been to the conference center \n",
       "only once, and I'm not sure if I can find my way around there.\n",
       "### Response :\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "### Instruction: \n",
       "Write a concise summary of the below input text.Ensure that responses covers the key points of the text.Only \n",
       "provide full sentence responses.\n",
       "### Input: \n",
       "#Person1#: Mister Ewing said we should show up at the conference center at \u001b[1;92m4:00\u001b[0m o'clock, right?\n",
       "#Person2#: Yes, he especially asked us not to be late. Some of the people from our east york branch office are \n",
       "coming, and he wants to make a good impression on them. How are you getting there?\n",
       "#Person1#: I was thinking of taking my car, but I think I'm just going to take the underground, because there is \n",
       "construction on the highway. What about you?\n",
       "#Person2#: I'll be taking the underground as well. Why don't we go together? I've been to the conference center \n",
       "only once, and I'm not sure if I can find my way around there.\n",
       "### Response :\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The meeting will start at four in the afternoon according to Mr. Ewing who has requested for everyone to arrive early so they do not miss out anything important during the event. He also mentioned that some members from their East York Branch Office would attend this meeting which means it’s very crucial since these individuals have never\n"
     ]
    }
   ],
   "source": [
    "print(text)\n",
    "result = generate(text, merged_model_from_disk,max_new_tokens=64, temp = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9469bf85-7598-404e-9629-7a04ee4788c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del merged_model_from_disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7891dd5c-bd1a-4df5-85f5-956af0f6e2e4",
   "metadata": {},
   "source": [
    "## Quantize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a0fdab5-15b8-43b2-8d00-b0bac153833c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'merged_model'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7373ac2-d526-4190-ae7a-cdf7a98e0dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9276007065b14c6ea75fc2f680ef8329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76251d378b8f447aab6bdf1dd8d2bae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing model.layers blocks :   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 47min 34s, sys: 15min 59s, total: 2h 3min 34s\n",
      "Wall time: 1h 46min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from transformers import GPTQConfig\n",
    "\n",
    "quantization_config = GPTQConfig(\n",
    "    bits=quantization_bits,\n",
    "    dataset=[\"c4\"],\n",
    "    desc_act=False,\n",
    ")\n",
    "\n",
    "quant_model = AutoModelForCausalLM.from_pretrained(\n",
    "    merged_dir, \n",
    "    quantization_config=quantization_config, \n",
    "    device_map=device\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(merged_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e35e993-b47b-42c8-b683-4c243f693d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del persisted_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5297fcab-e846-42d4-a32f-e233dd673d30",
   "metadata": {},
   "source": [
    "## Save quantized model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acc207ed-e2a3-4af9-920c-7c447a2bd2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chat_summarizer/quantized_8bit'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8431321-8378-42e4-b14b-81ab9fbd31ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">saving to chat_summarizer/quantized_8bit\n",
       "</pre>\n"
      ],
      "text/plain": [
       "saving to chat_summarizer/quantized_8bit\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.3 s, sys: 1.84 s, total: 4.13 s\n",
      "Wall time: 9.19 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('chat_summarizer/quantized_8bit/tokenizer_config.json',\n",
       " 'chat_summarizer/quantized_8bit/special_tokens_map.json',\n",
       " 'chat_summarizer/quantized_8bit/tokenizer.model',\n",
       " 'chat_summarizer/quantized_8bit/added_tokens.json',\n",
       " 'chat_summarizer/quantized_8bit/tokenizer.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "quant_path = os.path.join(project_dir, quantization_dir)\n",
    "print(f\"saving to {quant_path}\")\n",
    "\n",
    "# Save the quantized model\n",
    "quant_model.save_pretrained(quant_path, safe_serialization=True)\n",
    "tokenizer.save_pretrained(quant_path)\n",
    "#del persisted_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63e7173-bce1-42d7-8b38-cd1684247665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d01927a-4ef2-4718-8f03-34caa6c19172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">chat_summarizer/quantized_8bit\n",
       "</pre>\n"
      ],
      "text/plain": [
       "chat_summarizer/quantized_8bit\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 6.7G\n",
      "   0 drwxr-xr-x 1 root root 4.0K Nov  6 08:53 ..\n",
      "4.0K -rw-r--r-- 1 root root 1.2K Nov  6 08:53 config.json\n",
      "   0 -rw-r--r-- 1 root root  183 Nov  6 08:53 generation_config.json\n",
      "6.7G -rw-r--r-- 1 root root 6.7G Nov  6 08:53 model.safetensors\n",
      "4.0K -rw-r--r-- 1 root root  900 Nov  6 08:53 tokenizer_config.json\n",
      "   0 -rw-r--r-- 1 root root  414 Nov  6 08:53 special_tokens_map.json\n",
      "492K -rw-r--r-- 1 root root 489K Nov  6 08:53 tokenizer.model\n",
      "   0 drwxr-xr-x 1 root root 4.0K Nov  6 08:53 .\n",
      "1.8M -rw-r--r-- 1 root root 1.8M Nov  6 08:53 tokenizer.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "print(quant_path)\n",
    "!ls -latrsh $quant_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d21bcd6-7817-48d2-965a-4fdd56b22d28",
   "metadata": {},
   "source": [
    "## Load quantized model from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d47bde57-c8ba-4667-95ad-5d00ddf8b2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">chat_summarizer/quantized_8bit\n",
       "</pre>\n"
      ],
      "text/plain": [
       "chat_summarizer/quantized_8bit\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "print(quant_path)\n",
    "quant_model_from_disk = AutoModelForCausalLM.from_pretrained( quant_path, device_map=device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(quant_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "355987cd-30e6-4190-b6f2-c9c580869f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">### Instruction: \n",
       "Write a concise summary of the below input text.Ensure that responses covers the key points of the text.Only \n",
       "provide full sentence responses.\n",
       "### Input: \n",
       "#Person1#: Mister Ewing said we should show up at the conference center at <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">4:00</span> o'clock, right?\n",
       "#Person2#: Yes, he especially asked us not to be late. Some of the people from our east york branch office are \n",
       "coming, and he wants to make a good impression on them. How are you getting there?\n",
       "#Person1#: I was thinking of taking my car, but I think I'm just going to take the underground, because there is \n",
       "construction on the highway. What about you?\n",
       "#Person2#: I'll be taking the underground as well. Why don't we go together? I've been to the conference center \n",
       "only once, and I'm not sure if I can find my way around there.\n",
       "### Response :\n",
       " \n",
       " ==============================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "### Instruction: \n",
       "Write a concise summary of the below input text.Ensure that responses covers the key points of the text.Only \n",
       "provide full sentence responses.\n",
       "### Input: \n",
       "#Person1#: Mister Ewing said we should show up at the conference center at \u001b[1;92m4:00\u001b[0m o'clock, right?\n",
       "#Person2#: Yes, he especially asked us not to be late. Some of the people from our east york branch office are \n",
       "coming, and he wants to make a good impression on them. How are you getting there?\n",
       "#Person1#: I was thinking of taking my car, but I think I'm just going to take the underground, because there is \n",
       "construction on the highway. What about you?\n",
       "#Person2#: I'll be taking the underground as well. Why don't we go together? I've been to the conference center \n",
       "only once, and I'm not sure if I can find my way around there.\n",
       "### Response :\n",
       " \n",
       " ==============================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The meeting will start at four in the afternoon according to Mr. Ewing who has requested for everyone to arrive early so they do not miss out anything important during the event. He also mentioned that some members from their East York Branch Office would attend this meeting which means it’s very crucial since these individuals have never\n"
     ]
    }
   ],
   "source": [
    "print(text,\"\\n\",\"=\"*30)\n",
    "result = generate(text, quant_model_from_disk,max_new_tokens=64, temp = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2e5cefb-746c-4e92-854b-16f3ff2bfdea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I think this is one of those times when we should be thankful for what we already have and stop trying to get more stuff. We don’t need any new clothes or accessories; our wardrobes are filled up as they can possibly be without looking like we just stepped out of some thrift store'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2bf0f3-489f-41ac-b217-f0e0231c5b79",
   "metadata": {},
   "source": [
    "## Push model to HuggingFace hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81ccf35c-da18-49a5-a314-3af228d0fe6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "485348c99ec148debf2838d5a82f5cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/7.16G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27 s, sys: 7.34 s, total: 34.3 s\n",
      "Wall time: 4min 43s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/andersonjas/llama2-7b-dialogsum-qlora-gptq/commit/4e4225ff8fe753c5211bd62c00a23f0dfba561c7', commit_message='Upload LlamaForCausalLM', commit_description='', oid='4e4225ff8fe753c5211bd62c00a23f0dfba561c7', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer.push_to_hub(destination_hf_model_name, token=hf_token)\n",
    "quant_model_from_disk.push_to_hub(destination_hf_model_name, token = hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5556e7c9-97cc-4831-a765-33a7bf9ec4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.2 s, sys: 5.29 s, total: 14.5 s\n",
      "Wall time: 16.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# %%\n",
    "#from transformers import GPTQConfig\n",
    "\n",
    "# quantization_config = GPTQConfig(\n",
    "#     bits=4,\n",
    "#     dataset=[\"c4\"],\n",
    "#     desc_act=False,\n",
    "# )\n",
    "#quantization_config_loading = GPTQConfig(bits=4, disable_exllama=True)\n",
    "from_disk_quant_model = AutoModelForCausalLM.from_pretrained(\n",
    "    destination_hf_model_name, \n",
    "    #quantization_config=quantization_config_loading, \n",
    "    device_map=device,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(destination_hf_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab71ee7-6115-4358-b186-b2d856aeb216",
   "metadata": {},
   "source": [
    "## Test the model by pulling from hugging face hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7eb3d1fe-666e-4705-9761-f4fc3b2db399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">### Instruction: \n",
       "Write a concise summary of the below input text.Ensure that responses covers the key points of the text.Only \n",
       "provide full sentence responses.\n",
       "### Input: \n",
       "#Person1#: Mr. James. I know that office hour is up now, but could you work during the weekend and finish the \n",
       "translations?\n",
       "#Person2#: Well, unfortunately I have got something to do this weekend. But let me see<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "#Person1#: Oh, I'm sorry. However, if you could help me out, I'll double the pay for the hours worked.\n",
       "#Person2#: That's very kind of you. How soon do you really need them?\n",
       "#Person1#: I'll need them for the conference on Monday afternoon. Do you think it can be done by then?\n",
       "#Person2#: I'll try.\n",
       "#Person1#: Thank you very much, Mr. James.\n",
       "### Response :\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "### Instruction: \n",
       "Write a concise summary of the below input text.Ensure that responses covers the key points of the text.Only \n",
       "provide full sentence responses.\n",
       "### Input: \n",
       "#Person1#: Mr. James. I know that office hour is up now, but could you work during the weekend and finish the \n",
       "translations?\n",
       "#Person2#: Well, unfortunately I have got something to do this weekend. But let me see\u001b[33m...\u001b[0m\n",
       "#Person1#: Oh, I'm sorry. However, if you could help me out, I'll double the pay for the hours worked.\n",
       "#Person2#: That's very kind of you. How soon do you really need them?\n",
       "#Person1#: I'll need them for the conference on Monday afternoon. Do you think it can be done by then?\n",
       "#Person2#: I'll try.\n",
       "#Person1#: Thank you very much, Mr. James.\n",
       "### Response :\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr.James knows that he has an important meeting coming in next few days so he needs some extra hands from his colleague. He asks him whether he would like to join him over the weekends as well because there are many documents which still require translation. His friend agrees with him and says that he will definitely come forward to support him. They both discuss about how they should proceed further. Finally after having discussion ,\n"
     ]
    }
   ],
   "source": [
    "#text = test_df['text'][500]\n",
    "text = test_df['text'][4]\n",
    "print(text)\n",
    "result = generate(text, from_disk_quant_model, max_new_tokens=85,temp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d40f01a4-fb35-4e03-af5c-c4dd93566285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The above conversation took place during an informal meeting among two golf players who met each other by chance and decided to go out for a round of golf after their respective games ended. The first player (Jane) had recently moved into town from another state where she played regularly. She has been looking forward to joining her new community’s country club since moving there several months ago; however, due to lack of funds or interest in becoming involved with its activities until now when she finally found someone willing enough to take up golf as his hobby again despite having no prior experience whatsoever beforehand either through trial-and-error'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0534db9f-f3d6-41bc-b6a1-307ee1afedcb",
   "metadata": {},
   "source": [
    "# Train a GPTQ model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8edcc9e0-26fa-4f88-8c20-1f952953e77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed `quantization_config` to `from_pretrained` but the model you're loading already has a `quantization_config` attribute and has already quantized weights. However, loading attributes (e.g. disable_exllama, use_cuda_fp16, max_input_length) will be overwritten with the one you passed to `from_pretrained`. The rest will be ignored.\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_pandas(train_df)\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import prepare_model_for_kbit_training\n",
    "from transformers import GPTQConfig\n",
    "\n",
    "model_id = \"TheBloke/Llama-2-7B-GPTQ\"\n",
    "\n",
    "quantization_config_loading = GPTQConfig(bits=4, disable_exllama=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "                              model_id,\n",
    "                              quantization_config=quantization_config_loading,\n",
    "                              device_map=\"auto\"\n",
    "                          )\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model.config.use_cache = False\n",
    "# https://github.com/huggingface/transformers/pull/24906\n",
    "#disable tensor parallelism\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fbffaf8-038b-4612-a64d-799135ca5c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "from peft import LoraConfig, get_peft_model\n",
    "config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"k_proj\",\"o_proj\",\"q_proj\",\"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96e00d1c-04e2-4af5-aeb2-f40762898ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f6cef91cfa0>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f6cdd9bfe80, raw_cell=\"import transformers\n",
      "tokenizer.pad_token = tokenize..\" store_history=True silent=False shell_futures=True cell_id=96e00d1c-04e2-4af5-aeb2-f40762898ccc>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "582106f59b8b417690b61c93b168972f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11214 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 02:54, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.423000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.193400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.259900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.041900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.984800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.214300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.184400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.112500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.114100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.749300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.855500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.306300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.881600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.979100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.090400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.194500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.899300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.823700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.324600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.748100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.162200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.696300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.526200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.605600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.958500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.336800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.185900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.829900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.926200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.404400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.234400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.954300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>1.029900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.405800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.892000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.022600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.385900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.015800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.948500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.249400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.087100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.349900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.945000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.035700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.325400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.255700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.843400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.769300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.231900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.106000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.715600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.174200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.890700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.277000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.203600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.026300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.472200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.862100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>1.248400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>1.213700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>1.407800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1.323900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>1.225500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>1.102100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>1.264200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>1.280800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.055300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>1.538100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>1.114100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.815900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>1.129800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.897800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>1.150900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>1.500200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>1.071600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.799400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.061500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>1.439900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>1.123000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>1.080500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>1.013300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>1.445900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>1.717000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.812800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.849600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.723900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.128900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>1.391700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>1.419400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>1.149600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>1.053100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.606600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>1.130900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>1.240500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>1.297400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>1.071600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.490600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.927700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.950200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>1.423900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>1.166500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>1.270800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.751800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>1.171900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>1.195200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>1.065500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.860800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>0.843800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>1.490200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>0.898600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.973300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>1.196700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>0.927100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>1.086700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>1.177400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>1.175100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.524600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>1.111400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>1.115300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>1.168900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>1.265500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>1.262400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>1.338700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>1.201400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>1.380400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.312100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>1.211300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>1.102700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>1.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>1.489200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>1.199400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>1.143400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>1.299200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>0.981600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.157700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>1.049000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>0.908200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>1.320300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>1.344600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>1.019000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>1.084700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>0.819700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>1.453700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>1.310200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.370400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>1.315600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>0.926300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>0.966800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>1.183300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>0.751600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>1.207600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>1.979600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>0.978100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>1.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.965600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>1.626500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>1.160400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>1.072500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>1.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0.940600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>1.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>1.256900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>1.163600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>1.340300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.288500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>0.978200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>0.797200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>0.963800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>1.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.964200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>0.761700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>0.937100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>1.438500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>1.297500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.267900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>1.152800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>1.033700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>0.846500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>1.177500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>1.216000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>1.093900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>0.891800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>0.823700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>1.345800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.305000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>1.159600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.921700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>1.187100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>1.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>0.868200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>0.854700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>1.049200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>1.008400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>1.487900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.339500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201</td>\n",
       "      <td>1.003800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202</td>\n",
       "      <td>0.662300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203</td>\n",
       "      <td>0.953300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>1.370900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>0.818300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>0.979700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207</td>\n",
       "      <td>1.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208</td>\n",
       "      <td>1.376000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>209</td>\n",
       "      <td>1.289600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.986400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211</td>\n",
       "      <td>1.337800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>212</td>\n",
       "      <td>1.041200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213</td>\n",
       "      <td>0.775300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214</td>\n",
       "      <td>0.990700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>1.103300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>1.292900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217</td>\n",
       "      <td>1.671200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218</td>\n",
       "      <td>0.904200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>219</td>\n",
       "      <td>1.063200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.938800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>221</td>\n",
       "      <td>1.064900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>222</td>\n",
       "      <td>0.750300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>223</td>\n",
       "      <td>1.273200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>1.284000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.915900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>226</td>\n",
       "      <td>1.087900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227</td>\n",
       "      <td>1.135200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228</td>\n",
       "      <td>1.490900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>229</td>\n",
       "      <td>0.861800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.263600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>231</td>\n",
       "      <td>0.917600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>232</td>\n",
       "      <td>0.974300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233</td>\n",
       "      <td>1.205200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>234</td>\n",
       "      <td>1.354500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>0.806500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236</td>\n",
       "      <td>1.413900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>237</td>\n",
       "      <td>1.176000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>1.231500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239</td>\n",
       "      <td>0.765200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.224200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>241</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242</td>\n",
       "      <td>1.186600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>243</td>\n",
       "      <td>1.427400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244</td>\n",
       "      <td>0.720800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>1.065800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>1.177400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247</td>\n",
       "      <td>1.003700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>1.542300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>1.541100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.677200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>251</td>\n",
       "      <td>0.759100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>1.182400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>1.395000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>254</td>\n",
       "      <td>0.888600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>1.199900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>1.094500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257</td>\n",
       "      <td>1.207600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258</td>\n",
       "      <td>1.194100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>259</td>\n",
       "      <td>1.210700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.738900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>261</td>\n",
       "      <td>0.601200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>262</td>\n",
       "      <td>1.073800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>263</td>\n",
       "      <td>1.253600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264</td>\n",
       "      <td>1.413200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265</td>\n",
       "      <td>1.212000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>266</td>\n",
       "      <td>0.904200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>267</td>\n",
       "      <td>0.493200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>268</td>\n",
       "      <td>1.047900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>269</td>\n",
       "      <td>1.291800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.323800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>271</td>\n",
       "      <td>1.549500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>272</td>\n",
       "      <td>0.978600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>273</td>\n",
       "      <td>0.768500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>274</td>\n",
       "      <td>1.179400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>1.007500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>276</td>\n",
       "      <td>1.440800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>277</td>\n",
       "      <td>0.972800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>278</td>\n",
       "      <td>1.073500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>279</td>\n",
       "      <td>0.910600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.076200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>281</td>\n",
       "      <td>1.331000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>282</td>\n",
       "      <td>1.314400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>283</td>\n",
       "      <td>0.757400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284</td>\n",
       "      <td>0.968600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>1.307800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286</td>\n",
       "      <td>0.754500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>287</td>\n",
       "      <td>0.897600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>1.014100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>289</td>\n",
       "      <td>1.348100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.068800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>291</td>\n",
       "      <td>1.269100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292</td>\n",
       "      <td>1.063600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>293</td>\n",
       "      <td>1.159800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294</td>\n",
       "      <td>0.965300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>0.968900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>0.971600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297</td>\n",
       "      <td>1.123700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>1.066000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>1.538100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.973600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=300, training_loss=1.1282121592760086, metrics={'train_runtime': 174.8732, 'train_samples_per_second': 1.716, 'train_steps_per_second': 1.716, 'total_flos': 78501617197056.0, 'train_loss': 1.1282121592760086, 'epoch': 0.03})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f6cef91cfa0>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f6cdd9bfcd0, execution_count=14 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f6cdd9bfe80, raw_cell=\"import transformers\n",
      "tokenizer.pad_token = tokenize..\" store_history=True silent=False shell_futures=True cell_id=96e00d1c-04e2-4af5-aeb2-f40762898ccc> result=TrainOutput(global_step=300, training_loss=1.1282121592760086, metrics={'train_runtime': 174.8732, 'train_samples_per_second': 1.716, 'train_steps_per_second': 1.716, 'total_flos': 78501617197056.0, 'train_loss': 1.1282121592760086, 'epoch': 0.03})>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=1,\n",
    "        warmup_steps=2,\n",
    "        max_steps=300,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=True, #use mixed precision training\n",
    "        logging_steps=1,\n",
    "        output_dir=quantized_train_path,\n",
    "        optim=\"adamw_hf\",\n",
    "        save_strategy=\"epoch\")\n",
    "\n",
    "from trl import SFTTrainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=config,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    packing=False,\n",
    "    max_seq_length=512)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d202c1e-a7dc-41f5-8019-e67825cbac23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 99M\n",
      "   0 drwxr-xr-x 1 root root 4.0K Nov  6 21:07 ..\n",
      "   0 drwxr-xr-x 1 root root 4.0K Nov  6 21:07 .\n",
      "4.0K -rw-r--r-- 1 root root  819 Nov  7 00:03 tokenizer_config.json\n",
      "   0 -rw-r--r-- 1 root root  434 Nov  7 00:03 special_tokens_map.json\n",
      "492K -rw-r--r-- 1 root root 489K Nov  7 00:03 tokenizer.model\n",
      "1.8M -rw-r--r-- 1 root root 1.8M Nov  7 00:03 tokenizer.json\n",
      "8.0K -rw-r--r-- 1 root root 4.5K Nov  7 00:03 training_args.bin\n",
      " 65M -rw-r--r-- 1 root root  65M Nov  7 00:03 optimizer.pt\n",
      "4.0K -rw-r--r-- 1 root root 1.1K Nov  7 00:03 scheduler.pt\n",
      " 36K -rw-r--r-- 1 root root  36K Nov  7 00:03 trainer_state.json\n",
      " 16K -rw-r--r-- 1 root root  14K Nov  7 00:03 rng_state.pth\n",
      "4.0K -rw-r--r-- 1 root root 2.8K Nov  7 00:03 README.md\n",
      " 33M -rw-r--r-- 1 root root  33M Nov  7 00:03 adapter_model.bin\n",
      "   0 -rw-r--r-- 1 root root  474 Nov  7 00:03 adapter_config.json\n"
     ]
    }
   ],
   "source": [
    "!ls -latrsh $quantized_train_path/checkpoint-300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "214a1258-4396-4007-9ca6-7cf5943ed85e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# To perform inference on the test dataset example load the model from the checkpoint\u001b[39;00m\n\u001b[1;32m      7\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_id)\n\u001b[0;32m----> 9\u001b[0m persisted_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoPeftModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquantized_train_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/checkpoint-300\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Some gen config knobs\u001b[39;00m\n\u001b[1;32m     16\u001b[0m generation_config \u001b[38;5;241m=\u001b[39m GenerationConfig(\n\u001b[1;32m     17\u001b[0m     penalty_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m, \n\u001b[1;32m     18\u001b[0m     do_sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     23\u001b[0m )\n",
      "File \u001b[0;32m/app/venv/lib/python3.10/site-packages/peft/auto.py:101\u001b[0m, in \u001b[0;36m_BaseAutoPeftModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, adapter_name, is_trainable, config, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot infer the auto class from the config, please make sure that you are loading the correct model for your task type.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m     )\n\u001b[0;32m--> 101\u001b[0m base_model \u001b[38;5;241m=\u001b[39m \u001b[43mtarget_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_model_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_target_peft_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    104\u001b[0m     base_model,\n\u001b[1;32m    105\u001b[0m     pretrained_model_name_or_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    110\u001b[0m )\n",
      "File \u001b[0;32m/app/venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:565\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    564\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 565\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m )\n",
      "File \u001b[0;32m/app/venv/lib/python3.10/site-packages/transformers/modeling_utils.py:3307\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3297\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3298\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   3300\u001b[0m     (\n\u001b[1;32m   3301\u001b[0m         model,\n\u001b[1;32m   3302\u001b[0m         missing_keys,\n\u001b[1;32m   3303\u001b[0m         unexpected_keys,\n\u001b[1;32m   3304\u001b[0m         mismatched_keys,\n\u001b[1;32m   3305\u001b[0m         offload_index,\n\u001b[1;32m   3306\u001b[0m         error_msgs,\n\u001b[0;32m-> 3307\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   3311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3314\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3315\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3318\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3319\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquantization_method\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mQuantizationMethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBITS_AND_BYTES\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3323\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3325\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_4bit \u001b[38;5;241m=\u001b[39m load_in_4bit\n\u001b[1;32m   3326\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_8bit \u001b[38;5;241m=\u001b[39m load_in_8bit\n",
      "File \u001b[0;32m/app/venv/lib/python3.10/site-packages/transformers/modeling_utils.py:3695\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   3693\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m low_cpu_mem_usage:\n\u001b[1;32m   3694\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fsdp_enabled() \u001b[38;5;129;01mor\u001b[39;00m is_fsdp_enabled_and_dist_rank_0():\n\u001b[0;32m-> 3695\u001b[0m         new_error_msgs, offload_index, state_dict_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3696\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3697\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3698\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloaded_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3699\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3700\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3701\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3702\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3703\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3705\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3706\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3707\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_quantized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3708\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3709\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3710\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3711\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_error_msgs\n\u001b[1;32m   3712\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/app/venv/lib/python3.10/site-packages/transformers/modeling_utils.py:741\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, loaded_state_dict_keys, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, is_quantized, is_safetensors, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m    738\u001b[0m     state_dict_index \u001b[38;5;241m=\u001b[39m offload_weight(param, param_name, state_dict_folder, state_dict_index)\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_quantized:\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;66;03m# For backward compatibility with older versions of `accelerate`\u001b[39;00m\n\u001b[0;32m--> 741\u001b[0m     \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mset_module_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mint8 \u001b[38;5;129;01mand\u001b[39;00m param_name\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSCB\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m state_dict\u001b[38;5;241m.\u001b[39mkeys():\n",
      "File \u001b[0;32m/app/venv/lib/python3.10/site-packages/accelerate/utils/modeling.py:317\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics)\u001b[0m\n\u001b[1;32m    315\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 317\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "from time import perf_counter\n",
    "from rich import print\n",
    "from transformers import GenerationConfig\n",
    "model_id = \"TheBloke/Llama-2-7B-GPTQ\"\n",
    "# To perform inference on the test dataset example load the model from the checkpoint\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "persisted_model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=quantized_train_path + \"/checkpoint-300\",\n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\")\n",
    "# Some gen config knobs\n",
    "generation_config = GenerationConfig(\n",
    "    penalty_alpha=0.6, \n",
    "    do_sample = True, \n",
    "    top_k=5, \n",
    "    temperature=0.5, \n",
    "    repetition_penalty=1.2,\n",
    "    max_new_tokens=100\n",
    ")\n",
    "start_time = perf_counter()\n",
    "outputs = persisted_model.generate(**inputs, generation_config=generation_config)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "end_time = perf_counter()\n",
    "output_time = end_time - start_time\n",
    "print(f\"Time taken for inference: {round(output_time,2)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8f64992-4b3e-4cbd-b3a2-9ca071315c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">### Instruction: \n",
       "Write a concise summary of the below input text.Ensure that responses covers the key points of the text.Only \n",
       "provide full sentence responses.\n",
       "### Input: \n",
       "#Person1#: Mister Ewing said we should show up at the conference center at <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">4:00</span> o'clock, right?\n",
       "#Person2#: Yes, he especially asked us not to be late. Some of the people from our east york branch office are \n",
       "coming, and he wants to make a good impression on them. How are you getting there?\n",
       "#Person1#: I was thinking of taking my car, but I think I'm just going to take the underground, because there is \n",
       "construction on the highway. What about you?\n",
       "#Person2#: I'll be taking the underground as well. Why don't we go together? I've been to the conference center \n",
       "only once, and I'm not sure if I can find my way around there.\n",
       "### Response :\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "### Instruction: \n",
       "Write a concise summary of the below input text.Ensure that responses covers the key points of the text.Only \n",
       "provide full sentence responses.\n",
       "### Input: \n",
       "#Person1#: Mister Ewing said we should show up at the conference center at \u001b[1;92m4:00\u001b[0m o'clock, right?\n",
       "#Person2#: Yes, he especially asked us not to be late. Some of the people from our east york branch office are \n",
       "coming, and he wants to make a good impression on them. How are you getting there?\n",
       "#Person1#: I was thinking of taking my car, but I think I'm just going to take the underground, because there is \n",
       "construction on the highway. What about you?\n",
       "#Person2#: I'll be taking the underground as well. Why don't we go together? I've been to the conference center \n",
       "only once, and I'm not sure if I can find my way around there.\n",
       "### Response :\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ms. #Person1# asks Mr. #Person2# how they will get to the conference center for their meeting with mr. ewing. They decide to travel by subway since it takes longer time than usual due to road constructions.\n",
      "### End:\n",
      "</s>\n"
     ]
    }
   ],
   "source": [
    "2#text = test_df['text'][500]\n",
    "text = test_df['text'][1]\n",
    "print(text)\n",
    "result = generate(text, persisted_model, max_new_tokens=185,temp=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9bbd26-29d3-4c71-85e5-6a7093327ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
