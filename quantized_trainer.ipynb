{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78437d00-0dfd-420f-9d1d-accf9a2cde82",
   "metadata": {},
   "source": [
    "The goal of this notebook is to distill down the essential compenents of training HF models in a way that is easy to port to a data pipeline and apply to new model training scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff4105b-66b9-43ed-81d8-9769e56f1df8",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5186aef3-01b0-4a1f-ad6e-9c99d46ca824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from rich import print\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from datetime import datetime;\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f647f4-e46c-4b7d-bb28-4e11e6d632ab",
   "metadata": {},
   "source": [
    "# Define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88eb322b-c949-4461-9d04-7e4d396d3e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023_11_12'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if True:\n",
    "    date_str = datetime.now().strftime(\"%Y_%m_%d\")\n",
    "date_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b85d9c78-ef0c-4d91-a9df-bd9c799da50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'work/work_for_2023_11_12/best_checkpoint'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_dir = \"work\"\n",
    "seed = 42 #reproducability  over training runs\n",
    "clobber_project_dir = False #wipe the project director clean\n",
    "project_dir = f\"work_for_{date_str}\" #project name, also used as wandb project name\n",
    "\n",
    "#creds\n",
    "hf_token = os.environ[\"HF_TOKEN\"]\n",
    "wandb_key = os.environ[\"WANDB_KEY\"]\n",
    "hf_account_name = os.environ[\"HF_ACCOUNT_NAME\"]\n",
    "\n",
    "#HF touchpoints\n",
    "hf_dataset_name = \"knkarthick/dialogsum\"\n",
    "source_hf_model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "\n",
    "checkpoint_dir = \"best_checkpoint\"\n",
    "quantization_dir = 'quantized_8bit'\n",
    "merged_dir = 'merged_model'\n",
    "quantized_train_dir = 'quant_trained_model_new'\n",
    "\n",
    "train_test_split_ratio = 0.05\n",
    "\n",
    "#LoRA hparams\n",
    "lora_r = 64  # rank\n",
    "lora_alpha = lora_r * 2\n",
    "lora_dropout = 0.05\n",
    "\n",
    "#training hparams\n",
    "epochs = 1\n",
    "max_steps = 100\n",
    "per_device_train_batch_size=1\n",
    "gradient_accumulation_steps=1\n",
    "early_stopping_patience = 3\n",
    "learning_rate = 1e-4\n",
    "logging_steps = 25\n",
    "device = \"cuda\"\n",
    "max_seq_length = 512\n",
    "#quantization params\n",
    "quantization_bits = 4\n",
    "\n",
    "destination_hf_model_name = f\"{hf_account_name}/llama2-7b-dialogsum-qlora-gptq\"\n",
    "project_path = os.path.join(work_dir,project_dir, checkpoint_dir)\n",
    "quant_path = os.path.join(project_dir, quantization_dir)\n",
    "quantized_train_path = os.path.join(project_dir, quantized_train_dir)\n",
    "merged_path = os.path.join(project_path, merged_dir)\n",
    "\n",
    "project_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d0fc97-fbe3-4097-9751-3feafcbf218b",
   "metadata": {},
   "source": [
    "## State of working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07ffbb7b-ca53-4226-a31f-407e141bc587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">work_for_2023_11_12\n",
       "</pre>\n"
      ],
      "text/plain": [
       "work_for_2023_11_12\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\n",
      "0 drwxr-xr-x 1 root root 4096 Nov 12 02:30 quant_trained_model_new\n",
      "0 drwxr-xr-x 1 root root 4096 Nov 12 02:30 .\n",
      "0 drwxr-xr-x 1 root root 4096 Nov 12 03:07 ..\n"
     ]
    }
   ],
   "source": [
    "print(project_dir)\n",
    "!mkdir -p $project_dir\n",
    "\n",
    "#Set clobber_project_dir to True to reset working directory\n",
    "if clobber_project_dir:\n",
    "    !rm -rf ./$project_dir\n",
    "\n",
    "!mkdir -p $project_dir\n",
    "\n",
    "!ls -latrs ./$project_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77d175a-1860-4ae4-a387-97981d2b3466",
   "metadata": {},
   "source": [
    "## Initiate wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "256352b0-c7c7-45a3-9e5a-2e25fcae01cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjason-anderson-professional\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/app/jupyter/lora_gptq/wandb/run-20231112_030824-6easaff6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jason-anderson-professional/work_for_2023_11_12/runs/6easaff6' target=\"_blank\">dulcet-fog-3</a></strong> to <a href='https://wandb.ai/jason-anderson-professional/work_for_2023_11_12' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jason-anderson-professional/work_for_2023_11_12' target=\"_blank\">https://wandb.ai/jason-anderson-professional/work_for_2023_11_12</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jason-anderson-professional/work_for_2023_11_12/runs/6easaff6' target=\"_blank\">https://wandb.ai/jason-anderson-professional/work_for_2023_11_12/runs/6easaff6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login(key = wandb_key)\n",
    "run = wandb.init(project=project_dir, job_type=\"training\", anonymous=\"allow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98c44be-3cb1-45d4-ba26-5fa6a1e39e46",
   "metadata": {},
   "source": [
    "# Process data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "274adcda-c2a1-4524-b964-75b69186daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def analyze_generation_params(text, model):\n",
    "    print(text,\"-\"*60)\n",
    "    results = []\n",
    "    for temp in np.linspace(.5,1.5,num = 5):\n",
    "        print(f\"temp {temp}:\",end=\"\")\n",
    "        results.append(generate(text, model, prompt=False, max_new_tokens=185,temp=temp))\n",
    "    \n",
    "    print(\"-\"*60)\n",
    "    results = []\n",
    "    for top_p in np.linspace(0,1,num = 11):\n",
    "        print(f\"top_p {top_p}:\",end=\"\")\n",
    "        results.append(generate(text, model, prompt=False, max_new_tokens=185,temp=.7, top_p=top_p))\n",
    "    \n",
    "    \n",
    "    print(\"-\"*60)\n",
    "    results = []\n",
    "    for top_k in np.linspace(0,100,num = 11,dtype=int):\n",
    "        print(f\"top_k {top_k}:\",end=\"\")\n",
    "        results.append(generate(text,  model, prompt=False, max_new_tokens=185, top_k=int(top_k)))\n",
    "    \n",
    "    print(\"-\"*60)\n",
    "    results = []\n",
    "    for do_sample in [True,False]:\n",
    "        print(f\"do_sample {do_sample}:\",end=\"\")\n",
    "        results.append(generate(text,  model, prompt=False, max_new_tokens=185, do_sample = do_sample, top_k=None))\n",
    "    \n",
    "    \n",
    "    print(\"-\"*60)\n",
    "    results = []\n",
    "    for repetition_penalty in np.linspace(1.,2.,num=11):\n",
    "        print(f\"repetition_penalty {repetition_penalty}:\",end=\"\")\n",
    "        results.append(generate(text,  model, prompt=False, max_new_tokens=48,repetition_penalty=repetition_penalty))\n",
    "    \n",
    "    print(\"-\"*60)\n",
    "    results = []\n",
    "    for typical_p in np.linspace(.1,.9,num=9):\n",
    "        print(f\"typical_p {typical_p}:\",end=\"\")\n",
    "        results.append(generate(text,  model, prompt=False, max_new_tokens=48,typical_p=typical_p))\n",
    "\n",
    "\n",
    "def generate(text, model, prompt=False, temp=0.7,top_k= 40, top_p = 0.1, do_sample = True, repetition_penalty = 1.23, typical_p = 1, guidance_scale = 1, max_new_tokens = 24,):\n",
    "    from transformers import TextStreamer\n",
    "    if prompt:\n",
    "        print(text,\"-\"*20)\n",
    "    streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=False)\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to('cuda')\n",
    "\n",
    "    # Call the generate method of the model with the given inputs and additional generation configurations.\n",
    "    outputs = model.generate(**inputs,  # \"inputs\" likely includes input_ids or prompts for generation.\n",
    "                           streamer=streamer,  # \"streamer\" not a standard parameter in HF documentation, likely custom for model-specific streaming.\n",
    "                           max_new_tokens=max_new_tokens,  # Sets the maximum number of new tokens to generate; range varies based on model and computational limits.\n",
    "                           temperature=temp,  # Controls randomness: lower->more deterministic, higher->more random; typically in range [0.5, 1.5].\n",
    "                           do_sample=do_sample,  # Enables sampling; when True, picks tokens based on probability distribution, rather than just most likely.\n",
    "                           top_p=top_p,  # Nucleus sampling: selects top p% probability tokens for sampling; range [0, 1].\n",
    "                           top_k=top_k,  # Top-k sampling: chooses from top k probability tokens; if k=0, it's the same as using no top-k.\n",
    "                           repetition_penalty=repetition_penalty,  # Penalizes repeated tokens; >1 discourages, <1 encourages repetition; typically close to 1.\n",
    "                           typical_p=typical_p,  # Typical sampling; selects tokens whose cumulative probability is above this threshold, range [0, 1], usually close to 1.\n",
    "                           guidance_scale=guidance_scale,  # Affects the scale of guidance in models that support it, like CTRL; standard range not well-defined.\n",
    "                           #seed=seed,  # Sets a seed for reproducibility; commented out, so not in use.\n",
    "                          )\n",
    "    generated_tokens = outputs[0].tolist()[len(inputs[0]):]\n",
    "    result = tokenizer.decode(generated_tokens)\n",
    "    return result\n",
    "\n",
    "def set_plot_appearance(fontsize_title=14, \n",
    "                        fontsize_label=12, \n",
    "                        fontsize_ticks=8, \n",
    "                        theme='dark'):\n",
    "    \"\"\"\n",
    "    Configure the plot's appearance with font sizes and theme for dark backgrounds.\n",
    "    \n",
    "    Parameters:\n",
    "    fontsize_title: Font size for the title.\n",
    "    fontsize_label: Font size for the x and y labels.\n",
    "    fontsize_ticks: Font size for the x and y tick labels.\n",
    "    theme: Seaborn theme for the plot's aesthetic style.\n",
    "    \"\"\"\n",
    "    sns.set_theme(style=theme, palette='pastel')\n",
    "    \n",
    "    plt.rcParams.update({\n",
    "        'figure.facecolor': '#1a1a1a',  # Very dark grey background for the figure\n",
    "        'axes.facecolor': '#1a1a1a',    # Very dark grey background for the plots\n",
    "        'grid.color': 'gray',           # Lighter grey grid lines (less contrast)\n",
    "        'text.color': 'white',          # White text for better contrast on dark bg\n",
    "        'axes.labelcolor': 'white',     # White labels for axes\n",
    "        'xtick.color': 'white',         # White x-tick labels\n",
    "        'ytick.color': 'white',         # White y-tick labels\n",
    "        'axes.labelsize': fontsize_label,\n",
    "        'axes.titlesize': fontsize_title,\n",
    "        'xtick.labelsize': fontsize_ticks,\n",
    "        'ytick.labelsize': fontsize_ticks,\n",
    "        'legend.title_fontsize': fontsize_ticks + 2,\n",
    "        'legend.fontsize': fontsize_ticks,\n",
    "        'axes.edgecolor': 'lightgrey',  # Light grey color for the axes' spines\n",
    "    })\n",
    "# Possible modern themes: 'darkgrid', 'whitegrid', 'dark', 'white', and 'ticks'.\n",
    "# Example usage: set_plot_appearance(theme='ticks')\n",
    "\n",
    "def plot_text_length_histogram(df, bucket_size=64, percentile=95):\n",
    "    \"\"\"\n",
    "    Plot a histogram of text lengths and indicate the percentile.\n",
    "\n",
    "    Parameters:\n",
    "    df: the pandas dataframe to render from\n",
    "    bucket_size: the number of characters to bucket the histogram with\n",
    "    percentile: draws a vertical line at this percentile to visualize whether an acceptable fraction of the data lenghts are being used for training set\n",
    "    \"\"\"\n",
    "    set_plot_appearance()  # Apply appearance settings to the plot\n",
    "    text_lengths = df['text'].apply(len)  # Calculate text lengths.\n",
    "    bins = range(0, max(text_lengths) + bucket_size, bucket_size)  # Define histogram bins.\n",
    "    percentile_value = np.percentile(text_lengths, percentile)  # Calculate percentile value.\n",
    "\n",
    "    fig, ax = plt.subplots()  # Create figure and axis objects.\n",
    "    ax.hist(text_lengths, bins=bins, edgecolor='black', alpha=0.7)  # Plot histogram.\n",
    "    ax.axvline(x=percentile_value, color='red', linestyle='--')  # Draw percentile line.\n",
    "    \n",
    "    # Annotate the percentile line.\n",
    "    ax.text(percentile_value, ax.get_ylim()[1]*0.9, f' {percentile}th Percentile: {int(round(percentile_value, -1))}',\n",
    "            color='red', ha='left')\n",
    "\n",
    "    ax.set_xlabel('Text Length')  # Set x-axis label.\n",
    "    ax.set_ylabel('Frequency')  # Set y-axis label.\n",
    "    ax.set_title('Histogram of Text Lengths')  # Set title.\n",
    "\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))  # Set major locator for x-axis.\n",
    "    plt.show()  # Display the plot.\n",
    "\n",
    "def visualize_train_test_category_splits(train_df, test_df, top_x=5, normalize=True):\n",
    "    \"\"\"\n",
    "    Visualize the frequency of top categories in training and test datasets.\n",
    "    \"\"\"\n",
    "    set_plot_appearance()  # Apply appearance settings to the plot\n",
    "\n",
    "    # Get top x categories from both datasets.\n",
    "    train_topic_norm = train_df['topic'].value_counts(normalize=normalize).head(top_x)\n",
    "    test_topic_norm = test_df['topic'].value_counts(normalize=normalize).head(top_x)\n",
    "    \n",
    "    # Prepare the data for plotting.\n",
    "    train_topics = pd.DataFrame({'topic': train_topic_norm.index, 'frequency': train_topic_norm.values, 'dataset': 'Training'})\n",
    "    test_topics = pd.DataFrame({'topic': test_topic_norm.index, 'frequency': test_topic_norm.values, 'dataset': 'Test'})\n",
    "    combined_topics = pd.concat([train_topics, test_topics])\n",
    "\n",
    "    sns.barplot(x='frequency', y='topic', hue='dataset', data=combined_topics)  # Create bar plot.\n",
    "    plt.title('Top {} Topics Frequency Comparison'.format(top_x))  # Set title.\n",
    "    plt.xlabel('Normalized Frequency')  # Set x-axis label.\n",
    "    plt.ylabel('Topic')  # Set y-axis label.\n",
    "    plt.tight_layout()  # Adjust layout.\n",
    "    plt.show()  # Display the plot.\n",
    "\n",
    "\n",
    "\n",
    "def get_data_stuff(dataset_name, split_ratio=0.2):    \n",
    "    # %%\n",
    "    from datasets import load_dataset\n",
    "    from datasets import Dataset\n",
    "    import pandas as pd\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    \n",
    "    \n",
    "    #load the dataset\n",
    "    dataset = load_dataset(dataset_name)\n",
    "    \n",
    "    # Shuffle the dataset (setting seed for reproducibility)\n",
    "    shuffled_ds = dataset['train']#.shuffle(seed=seed)\n",
    "    #shuffled_ds = shuffled_ds.select(range(1000))\n",
    "\n",
    "    \n",
    "    # Split the dataset into training and test sets with a test size of 20%\n",
    "    train_test_split = shuffled_ds.train_test_split(test_size=train_test_split_ratio, seed = seed)\n",
    "    \n",
    "    # The train/test datasets are now accessible as follows:\n",
    "    train_ds = train_test_split['train']\n",
    "    raw_train_df = pd.DataFrame(train_ds)\n",
    "    \n",
    "    test_ds = train_test_split['test']\n",
    "    raw_test_df = pd.DataFrame(test_ds)\n",
    "    \n",
    "    prepared_train_df = prepare_dataset(raw_train_df, \"train\")\n",
    "    prepared_test_df = prepare_dataset(raw_test_df, \"test\")\n",
    "\n",
    "    prepared_train_dataset = Dataset.from_pandas(prepared_train_df)\n",
    "    prepared_test_dataset = Dataset.from_pandas(prepared_test_df)\n",
    "    \n",
    "    print(f\"length of downloaded ds: {len(shuffled_ds)}\")\n",
    "    print(f\"length of train_ds: {len(prepared_train_dataset)}\")\n",
    "    print(f\"length of test_ds: {len(prepared_test_dataset)}\")\n",
    "    estimated_training_steps = epochs * len(prepared_train_dataset) / per_device_train_batch_size / gradient_accumulation_steps\n",
    "    print(f\"estimated training steps will be {estimated_training_steps}\")\n",
    "    return prepared_train_df, prepared_test_df, prepared_train_dataset, prepared_test_dataset\n",
    "\n",
    "\n",
    "def prepare_dataset(df, split=\"train\"):\n",
    "    text_col = []\n",
    "    instruction = \"\"\"Write a concise summary of the below input text.Ensure that responses covers the key points of the text.Only provide full sentence responses.\"\"\"  # change instuction according to the task\n",
    "    if split == \"train\":\n",
    "        for _, row in df.iterrows():\n",
    "            input_q = row[\"dialogue\"]\n",
    "            output = row[\"summary\"]\n",
    "            text = (\n",
    "                \"### Instruction: \\n\"\n",
    "                + instruction\n",
    "                + \"\\n### Input: \\n\"\n",
    "                + input_q\n",
    "                + \"\\n### Response :\\n\"\n",
    "                + output\n",
    "                + \"\\n### End\"\n",
    "            )  # keeping output column in training dataset\n",
    "            text_col.append(text)\n",
    "        df.loc[:, \"text\"] = text_col\n",
    "    else:\n",
    "        for _, row in df.iterrows():\n",
    "            input_q = row[\"dialogue\"]\n",
    "            text = (\n",
    "                \"### Instruction: \\n\"\n",
    "                + instruction\n",
    "                + \"\\n### Input: \\n\"\n",
    "                + input_q\n",
    "                + \"\\n### Response :\\n\"\n",
    "            )  # not keeping output column in test dataset\n",
    "            text_col.append(text)\n",
    "        df.loc[:, \"text\"] = text_col\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a764bbf-2d24-410d-9356-68f2153af13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">length of downloaded ds: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12460</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "length of downloaded ds: \u001b[1;36m12460\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">length of train_ds: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11837</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "length of train_ds: \u001b[1;36m11837\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">length of test_ds: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">623</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "length of test_ds: \u001b[1;36m623\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">estimated training steps will be <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11837.0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "estimated training steps will be \u001b[1;36m11837.0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df, test_df, train_dataset, test_dataset = get_data_stuff(hf_dataset_name, \n",
    "                                                                split_ratio=train_test_split_ratio,\n",
    "                                                               )\n",
    "text = test_df['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46b9d045-f3df-45b3-beea-92336c089d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">### Instruction: \n",
       "Write a concise summary of the below input text.Ensure that responses covers the key points of the text.Only \n",
       "provide full sentence responses.\n",
       "### Input: \n",
       "#Person1#: Mister Ewing said we should show up at the conference center at <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">4:00</span> o'clock, right?\n",
       "#Person2#: Yes, he especially asked us not to be late. Some of the people from our east york branch office are \n",
       "coming, and he wants to make a good impression on them. How are you getting there?\n",
       "#Person1#: I was thinking of taking my car, but I think I'm just going to take the underground, because there is \n",
       "construction on the highway. What about you?\n",
       "#Person2#: I'll be taking the underground as well. Why don't we go together? I've been to the conference center \n",
       "only once, and I'm not sure if I can find my way around there.\n",
       "### Response :\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "### Instruction: \n",
       "Write a concise summary of the below input text.Ensure that responses covers the key points of the text.Only \n",
       "provide full sentence responses.\n",
       "### Input: \n",
       "#Person1#: Mister Ewing said we should show up at the conference center at \u001b[1;92m4:00\u001b[0m o'clock, right?\n",
       "#Person2#: Yes, he especially asked us not to be late. Some of the people from our east york branch office are \n",
       "coming, and he wants to make a good impression on them. How are you getting there?\n",
       "#Person1#: I was thinking of taking my car, but I think I'm just going to take the underground, because there is \n",
       "construction on the highway. What about you?\n",
       "#Person2#: I'll be taking the underground as well. Why don't we go together? I've been to the conference center \n",
       "only once, and I'm not sure if I can find my way around there.\n",
       "### Response :\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe3b1874-38b3-406c-a9c3-ce34e42f1f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#to enhance training, consider rolling the shuffle dice until you get good consistency between training and test set categories.\n",
    "visualize_train_test_category_splits(train_df, test_df, top_x=5, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b8f0497-7b16-406e-b3dc-3f0c265fdc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#this just measures space-delimited words which isn't necessarily the same as toke count, but it should be close-ish\n",
    "plot_text_length_histogram(train_df, percentile = 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad76bea-cf16-49eb-aa88-41f7a4aa8b95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0534db9f-f3d6-41bc-b6a1-307ee1afedcb",
   "metadata": {},
   "source": [
    "# Train from a previously qptq-quantized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2d277d9-7462-4c63-9b20-d0c904129cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/venv/lib/python3.10/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n",
      "You passed `quantization_config` to `from_pretrained` but the model you're loading already has a `quantization_config` attribute and has already quantized weights. However, loading attributes (e.g. disable_exllama, use_cuda_fp16, max_input_length) will be overwritten with the one you passed to `from_pretrained`. The rest will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 16,777,216 || all params: 279,187,456 || trainable%: 6.009301506726721\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ffdb1f697374a8c891365f7e708e500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11837 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19388c1021d41cb8ff08e7215726c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/623 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/venv/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/app/venv/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 09:03, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.365600</td>\n",
       "      <td>1.217867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.124300</td>\n",
       "      <td>1.207811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.130800</td>\n",
       "      <td>1.203843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.108000</td>\n",
       "      <td>1.202743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">work_for_2023_11_12/quant_trained_model_new/final_checkpoints_gptqsummarizer_7b_peft\n",
       "</pre>\n"
      ],
      "text/plain": [
       "work_for_2023_11_12/quant_trained_model_new/final_checkpoints_gptqsummarizer_7b_peft\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 65M\n",
      "  0 drwxr-xr-x 1 root root 4.0K Nov 12 03:18 ..\n",
      "  0 -rw-r--r-- 1 root root  525 Nov 12 03:18 README.md\n",
      "65M -rw-r--r-- 1 root root  65M Nov 12 03:18 adapter_model.bin\n",
      "  0 drwxr-xr-x 1 root root 4.0K Nov 12 03:18 .\n",
      "  0 -rw-r--r-- 1 root root  475 Nov 12 03:18 adapter_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from peft import prepare_model_for_kbit_training\n",
    "from transformers import GPTQConfig\n",
    "from transformers import Trainer, TrainingArguments #, DataCollatorForLanguageModeling\n",
    "from trl import SFTTrainer\n",
    "\n",
    "quant_model_id = \"TheBloke/Llama-2-7B-GPTQ\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(quant_model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "\n",
    "quantization_config_loading = GPTQConfig(bits=4, \n",
    "                                         disable_exllama=True,\n",
    "                                        )\n",
    "config = LoraConfig(\n",
    "                            r=16,\n",
    "                            lora_alpha=32,\n",
    "                            target_modules=[\"k_proj\",\"o_proj\",\"q_proj\",\"v_proj\"],\n",
    "                            lora_dropout=0.05,\n",
    "                            bias=\"none\",\n",
    "                            task_type=\"CAUSAL_LM\"\n",
    "                        )\n",
    "training_args=TrainingArguments(\n",
    "                                per_device_train_batch_size=4, # Batch size per device during training\n",
    "                                gradient_accumulation_steps=4, # Number of steps to accumulate gradients before updating model parameters\n",
    "                                warmup_steps=2, # Number of steps for the warm-up phase\n",
    "                                max_steps=max_steps, # Total number of training steps to perform\n",
    "                                learning_rate=2e-4, # Initial learning rate\n",
    "                                fp16=True, # Enable mixed precision training to improve performance\n",
    "                                logging_steps=25, # Frequency of logging training information\n",
    "                                output_dir=quantized_train_path, # Directory for saving output (like model checkpoints)\n",
    "                                optim=\"adamw_hf\", # Optimizer to be used for training, here it's a variant of AdamW from Hugging Face\n",
    "                                save_strategy=\"steps\", # Strategy for saving model checkpoints (here, at the end of each epoch)\n",
    "                                report_to=\"none\", # Disable reporting to any external services\n",
    "                                evaluation_strategy=\"steps\",  # Add this line\n",
    "                                eval_steps=logging_steps,  # Add this line\n",
    "                                metric_for_best_model=\"loss\",\n",
    "                                greater_is_better=False,\n",
    "                                load_best_model_at_end=True,\n",
    "                            )\n",
    "\n",
    "\n",
    "quant_model = AutoModelForCausalLM.from_pretrained(quant_model_id, \n",
    "                                             quantization_config=quantization_config_loading, \n",
    "                                             device_map=\"auto\",\n",
    "                                            )\n",
    "\n",
    "\n",
    "quant_model.config.use_cache = False\n",
    "quant_model.config.pretraining_tp = 1\n",
    "quant_model.gradient_checkpointing_enable()\n",
    "\n",
    "prepared_model = prepare_model_for_kbit_training(quant_model)\n",
    "peft_model = get_peft_model(prepared_model, config)\n",
    "peft_model.print_trainable_parameters()\n",
    "peft_model.config.use_cache = False # silence the warnings. Please re-enable for inference!\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "    #peft_config=lora_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    packing=False,\n",
    "    max_seq_length=max_seq_length,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=early_stopping_patience)],\n",
    ")\n",
    "\n",
    "train_result = trainer.train()\n",
    "#Also I noticed that you pass a PeftModel to SFTTrainer together with a peft_config argument, this might lead to create a nested peft model which can lead to some bugs.\n",
    "\n",
    "\n",
    "checkpoint_name =\"final_checkpoints_gptqsummarizer_7b_peft\"\n",
    "output_dir = os.path.join(quantized_train_path, checkpoint_name)\n",
    "trainer.model.save_pretrained(output_dir)\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "# To perform inference on the test dataset example load the model from the checkpoint\n",
    "persisted_model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    output_dir,\n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cuda\",\n",
    ")\n",
    "\n",
    "print(output_dir)\n",
    "!ls -latrhs $output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85b5ce4a-bed3-4d79-9e7f-afdebf330750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">==============================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "==============================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ms. Smith will join Mr. Ewing in showing up for the meeting with some colleagues from their East York Branch Office. They decide to travel by subway since they have heard traffic congestion due to road constructions.\n",
      "### EndResponse #Person1# tells #Person2# how she plans to get to the conference center.\n",
      "### EndInput\n",
      "</s>\n"
     ]
    }
   ],
   "source": [
    "text = test_df['text'][1]\n",
    "print(\"=\"*30)\n",
    "result = generate(text, persisted_model, max_new_tokens=80, temp=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fe02b5c-6a32-419f-8daa-f82f2d74d4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">### Instruction: \n",
       "Write a concise summary of the below input text.Ensure that responses covers the key points of the text.Only \n",
       "provide full sentence responses.\n",
       "### Input: \n",
       "#Person1#: Mister Ewing said we should show up at the conference center at <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">4:00</span> o'clock, right?\n",
       "#Person2#: Yes, he especially asked us not to be late. Some of the people from our east york branch office are \n",
       "coming, and he wants to make a good impression on them. How are you getting there?\n",
       "#Person1#: I was thinking of taking my car, but I think I'm just going to take the underground, because there is \n",
       "construction on the highway. What about you?\n",
       "#Person2#: I'll be taking the underground as well. Why don't we go together? I've been to the conference center \n",
       "only once, and I'm not sure if I can find my way around there.\n",
       "### Response :\n",
       " ------------------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "### Instruction: \n",
       "Write a concise summary of the below input text.Ensure that responses covers the key points of the text.Only \n",
       "provide full sentence responses.\n",
       "### Input: \n",
       "#Person1#: Mister Ewing said we should show up at the conference center at \u001b[1;92m4:00\u001b[0m o'clock, right?\n",
       "#Person2#: Yes, he especially asked us not to be late. Some of the people from our east york branch office are \n",
       "coming, and he wants to make a good impression on them. How are you getting there?\n",
       "#Person1#: I was thinking of taking my car, but I think I'm just going to take the underground, because there is \n",
       "construction on the highway. What about you?\n",
       "#Person2#: I'll be taking the underground as well. Why don't we go together? I've been to the conference center \n",
       "only once, and I'm not sure if I can find my way around there.\n",
       "### Response :\n",
       " ------------------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">temp <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>:</pre>\n"
      ],
      "text/plain": [
       "temp \u001b[1;36m0.5\u001b[0m:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ms. Smith will join Mr. Ewing in showing up for the meeting with some colleagues from their East York Branch Office. They decide to travel by subway since they have heard traffic congestion due to road constructions.\n",
      "### EndResponse #Person1# tells #Person2# how she plans to get to the conference center.\n",
      "### EndInput\n",
      "</s>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">temp <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.75</span>:</pre>\n"
      ],
      "text/plain": [
       "temp \u001b[1;36m0.75\u001b[0m:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ms. Smith will join Mr. Ewing in showing up for the meeting with some colleagues from their East York Branch Office. They decide to travel by subway since they have heard traffic congestion due to road constructions.\n",
      "### EndResponse #Person1# tells #Person2# how she plans to get to the conference center.\n",
      "### EndInput\n",
      "</s>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">temp <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>:</pre>\n"
      ],
      "text/plain": [
       "temp \u001b[1;36m1.0\u001b[0m:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ms. Smith will join Mr. Ewing in showing up for the meeting with some colleagues from their East York Branch Office. They decide to travel by subway since they have heard traffic congestion due to road constructions.\n",
      "### EndResponse #Person1# tells #Person2# how she plans to get to the conference center.\n",
      "### EndInput\n",
      "</s>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">temp <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.25</span>:</pre>\n"
      ],
      "text/plain": [
       "temp \u001b[1;36m1.25\u001b[0m:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ms. Smith will join Mr. Ewing in showing up for the meeting with some colleagues from their East York Branch Office. They decide to travel by subway since they have heard traffic congestion due to road constructions.\n",
      "### EndResponse #Person1# tells #Person2# how she plans to get to the conference center.\n",
      "### EndInput\n",
      "</s>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">temp <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.5</span>:</pre>\n"
      ],
      "text/plain": [
       "temp \u001b[1;36m1.5\u001b[0m:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ms. Smith will meet Mr. Ewing in the conference center with #Person1#, who takes his car for traffic congestion. They both decide to take the subway instead.\n",
      "### EndResponse ##\n",
      "### InSummarizeTaskEnd ##\n",
      "</s>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">------------------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "------------------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">top_p <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>:</pre>\n"
      ],
      "text/plain": [
       "top_p \u001b[1;36m0.0\u001b[0m:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ms. Smith will join Mr. Ewing in showing up for the meeting with some colleagues from their East York Branch Office. They decide to travel by subway since they have heard traffic congestion due to road constructions.\n",
      "### EndResponse #Person1# tells #Person2# how she plans to get to the conference center.\n",
      "### EndInput\n",
      "</s>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">top_p <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>:</pre>\n"
      ],
      "text/plain": [
       "top_p \u001b[1;36m0.1\u001b[0m:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ms. Smith will join Mr. Ewing in showing up for the meeting with some colleagues from their East York Branch Office. They decide to travel by subway since they have heard traffic congestion due to road constructions.\n",
      "### EndResponse #Person1# tells #Person2# how she plans to get to the conference center.\n",
      "### EndInput\n",
      "</s>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">top_p <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>:</pre>\n"
      ],
      "text/plain": [
       "top_p \u001b[1;36m0.2\u001b[0m:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ms. Smith will meet Mr. Ewing in the conference center with #Person1#, who takes his car for traffic congestion. They both decide to take the subway instead.\n",
      "### EndResponse ##\n",
      "### InSummarizeTaskEnd ##\n",
      "</s>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">top_p <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.30000000000000004</span>:</pre>\n"
      ],
      "text/plain": [
       "top_p \u001b[1;36m0.30000000000000004\u001b[0m:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ms. Smith will join Mr. Ewing in showing up for the meeting at 4 pm today since they both plan to use public transportation due to traffic congestion.\n",
      "### EndResponse #Person2#\n",
      "### EndInput #Person1#</s>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">top_p <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4</span>:</pre>\n"
      ],
      "text/plain": [
       "top_p \u001b[1;36m0.4\u001b[0m:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ms. Smith will drive her own car while Mr. Brown takes the subway with #Person1#, who also plans to use it for convenience. They both want to get to the meeting place early so they won't miss anything important.\n",
      "### EndResponse ##\n",
      "### InSummarize:\n",
      "Mr. Brown suggests driving his car instead of using public transportation since traffic may cause trouble in finding their destination. But Ms. Smith thinks she would rather take the train due to its convenience. So do they decide to travel by themselves or join each other.\n",
      "### EndInSummarize\n",
      "</s>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">top_p <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>:</pre>\n"
      ],
      "text/plain": [
       "top_p \u001b[1;36m0.5\u001b[0m:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mrs. Wong asks Mr. Ewing what time they need to arrive for their meeting with some people from East York Branch Office in the Conference Center. They decide to take the subway since it will save time due to traffic jam caused by road constructions.\n",
      "### EndResponse ?\n",
      "### Include?\n",
      "### Cover?</s>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">top_p <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6000000000000001</span>:</pre>\n"
      ],
      "text/plain": [
       "top_p \u001b[1;36m0.6000000000000001\u001b[0m:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ms. Smith will meet Mr. Ewing in the meeting room for the conference. They both decide to use public transportation since they need to get ready early.\n",
      "### End Response\n",
      "### Finish the summary with one or two sentences covering all main ideas of this response.\n",
      "### Only provide full sentence responses.</s>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">top_p <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7000000000000001</span>:</pre>\n"
      ],
      "text/plain": [
       "top_p \u001b[1;36m0.7000000000000001\u001b[0m:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ms. Wong tells Mr. Lee she will get to the meeting place by train since it would take longer time for her to drive through traffic jams caused by road constructions. They decide they both ride trains so that one person could help another when lost in the new environment.\n",
      "### EndResponse ?\n",
      "### Conclusion:\n",
      "Mr. Lee decides to join #Person1# riding an underground instead of driving his own car due to the traffic jam caused by road constructions.</s>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">top_p <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8</span>:</pre>\n"
      ],
      "text/plain": [
       "top_p \u001b[1;36m0.8\u001b[0m:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ms. Jones tells #Person1# she will take her car while Mr. Ewing asks for their arrival time. They decide they will travel by subway since it would save some traffic jam trouble in case there is one due to road works.\n",
      "### EndResponse\n",
      "### InConclusion:\n",
      "Mr. Ewing has arranged an important meeting with his colleagues from other branches. He expects everyone arrive punctually so that all participants could have enough time to prepare themselves beforehand. Meanwhile, both Ms. Jones and Mr. Ewing plan to drive or ride trains instead of cars which might cause troubles during rush hours.\n",
      "</s>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">top_p <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span>:</pre>\n"
      ],
      "text/plain": [
       "top_p \u001b[1;36m0.9\u001b[0m:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary tells #Person2# she will join her in driving to the meeting place. Mary says they need to arrive early since some guests come by bus or train.\n",
      "### End Response ##\n",
      "### Personal Feedback:\n",
      "Mary plans to drive with #Person2#, while #Person2# prefers taking public transportation due to traffic problems. They agree to meet each other first before heading for their destination.</s>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">top_p <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>:</pre>\n"
      ],
      "text/plain": [
       "top_p \u001b[1;36m1.0\u001b[0m:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mike tells #Person1# they need to arrive early for an important meeting tomorrow. They will both drive their cars before taking any other transportation means due to traffic jams caused by road constructions.\n",
      "### End Response ##\n",
      "### Inserts:\n",
      "Construction Transportation Roadways Transport Systems Underground Railroads Conferences</s>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">------------------------------------------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "------------------------------------------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">top_k <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>:</pre>\n"
      ],
      "text/plain": [
       "top_k \u001b[1;36m0\u001b[0m:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ms. Smith will join Mr. Ewing in showing up for the meeting with some colleagues from their East York Branch Office. They decide to travel by subway since they have heard traffic congestion due to road constructions.\n",
      "### EndResponse #Person1# tells #Person2# how she plans to get to the conference center.\n",
      "### EndInput\n",
      "</s>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">top_k <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>:</pre>\n"
      ],
      "text/plain": [
       "top_k \u001b[1;36m10\u001b[0m:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ms. Smith will join Mr. Ewing in showing up for the meeting with some colleagues from their East York Branch Office. They decide to travel by subway since they have heard traffic congestion due to road constructions.\n",
      "### EndResponse #Person1# tells #Person2# how she plans to get to the conference center.\n",
      "### EndInput\n",
      "</s>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">top_k <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>:</pre>\n"
      ],
      "text/plain": [
       "top_k \u001b[1;36m20\u001b[0m:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ms. Smith will join Mr. Ewing in showing up for the meeting with some colleagues from their East York Branch Office. They decide to travel by subway since they have heard traffic congestion due to road constructions.\n",
      "### EndResponse #Person1# tells #Person2# how she plans to get to the conference center.\n",
      "### EndInput\n",
      "</s>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">top_k <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span>:</pre>\n"
      ],
      "text/plain": [
       "top_k \u001b[1;36m30\u001b[0m:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ms. Smith will join Mr. Ewing in showing up for the meeting with some colleagues from their East York Branch Office. They decide to travel by subway since they have heard traffic congestion due to road constructions.\n",
      "### EndResponse #Person1# tells #Person2# how she plans to get to the conference center.\n",
      "### EndInput\n",
      "</s>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">top_k <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>:</pre>\n"
      ],
      "text/plain": [
       "top_k \u001b[1;36m40\u001b[0m:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ms. Smith will join Mr. Ewing in showing up for the meeting with some colleagues from their East York Branch Office. They decide to travel by subway since they have heard traffic congestion due to road constructions.\n",
      "### EndResponse #Person1# tells #Person2# how she plans to get to the conference center.\n",
      "### EndInput\n",
      "</s>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">top_k <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>:</pre>\n"
      ],
      "text/plain": [
       "top_k \u001b[1;36m50\u001b[0m:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ms. Smith will join Mr. Ewing in showing up for the meeting with some colleagues from their East York Branch Office. They decide to travel by subway since they have heard traffic "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# repitition_penalty really blows test_df['text'][1] out of the water...`\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43manalyze_generation_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpersisted_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 28\u001b[0m, in \u001b[0;36manalyze_generation_params\u001b[0;34m(text, model)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m top_k \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m100\u001b[39m,num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m11\u001b[39m,dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_k \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtop_k\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m,end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m185\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m)\n\u001b[1;32m     31\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[6], line 58\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(text, model, prompt, temp, top_k, top_p, do_sample, repetition_penalty, typical_p, guidance_scale, max_new_tokens)\u001b[0m\n\u001b[1;32m     55\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Call the generate method of the model with the given inputs and additional generation configurations.\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# \"inputs\" likely includes input_ids or prompts for generation.\u001b[39;49;00m\n\u001b[1;32m     59\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# \"streamer\" not a standard parameter in HF documentation, likely custom for model-specific streaming.\u001b[39;49;00m\n\u001b[1;32m     60\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Sets the maximum number of new tokens to generate; range varies based on model and computational limits.\u001b[39;49;00m\n\u001b[1;32m     61\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Controls randomness: lower->more deterministic, higher->more random; typically in range [0.5, 1.5].\u001b[39;49;00m\n\u001b[1;32m     62\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Enables sampling; when True, picks tokens based on probability distribution, rather than just most likely.\u001b[39;49;00m\n\u001b[1;32m     63\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Nucleus sampling: selects top p% probability tokens for sampling; range [0, 1].\u001b[39;49;00m\n\u001b[1;32m     64\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Top-k sampling: chooses from top k probability tokens; if k=0, it's the same as using no top-k.\u001b[39;49;00m\n\u001b[1;32m     65\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepetition_penalty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Penalizes repeated tokens; >1 discourages, <1 encourages repetition; typically close to 1.\u001b[39;49;00m\n\u001b[1;32m     66\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mtypical_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtypical_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Typical sampling; selects tokens whose cumulative probability is above this threshold, range [0, 1], usually close to 1.\u001b[39;49;00m\n\u001b[1;32m     67\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mguidance_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mguidance_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Affects the scale of guidance in models that support it, like CTRL; standard range not well-defined.\u001b[39;49;00m\n\u001b[1;32m     68\u001b[0m \u001b[43m                       \u001b[49m\u001b[38;5;66;43;03m#seed=seed,  # Sets a seed for reproducibility; commented out, so not in use.\u001b[39;49;00m\n\u001b[1;32m     69\u001b[0m \u001b[43m                      \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m generated_tokens \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;28mlen\u001b[39m(inputs[\u001b[38;5;241m0\u001b[39m]):]\n\u001b[1;32m     71\u001b[0m result \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(generated_tokens)\n",
      "File \u001b[0;32m/app/venv/lib/python3.10/site-packages/peft/peft_model.py:975\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.generate\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model\u001b[38;5;241m.\u001b[39mgeneration_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 975\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model_prepare_inputs_for_generation\n",
      "File \u001b[0;32m/app/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/app/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1652\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1644\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1645\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1646\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1647\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1648\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1649\u001b[0m     )\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;66;03m# 13. run sample\u001b[39;00m\n\u001b[0;32m-> 1652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1653\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1657\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1658\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1659\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1660\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1661\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH:\n\u001b[1;32m   1667\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   1668\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   1669\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1670\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1675\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   1676\u001b[0m     )\n",
      "File \u001b[0;32m/app/venv/lib/python3.10/site-packages/transformers/generation/utils.py:2734\u001b[0m, in \u001b[0;36mGenerationMixin.sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2731\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2733\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2734\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2735\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2737\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2738\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2739\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2742\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m/app/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/app/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/app/venv/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1038\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1035\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1038\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1050\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/app/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/app/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/app/venv/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:925\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    921\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    922\u001b[0m         create_custom_forward(decoder_layer), hidden_states, attention_mask, position_ids\n\u001b[1;32m    923\u001b[0m     )\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 925\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    935\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/app/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/app/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/app/venv/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:635\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, padding_mask)\u001b[0m\n\u001b[1;32m    632\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    634\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 635\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    644\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    646\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m/app/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/app/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/app/venv/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:350\u001b[0m, in \u001b[0;36mLlamaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, padding_mask)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     query_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_proj(hidden_states)\n\u001b[0;32m--> 350\u001b[0m     key_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m     value_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj(hidden_states)\n\u001b[1;32m    353\u001b[0m query_states \u001b[38;5;241m=\u001b[39m query_states\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/app/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/app/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/app/venv/lib/python3.10/site-packages/peft/tuners/lora.py:1264\u001b[0m, in \u001b[0;36mQuantLinear.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1261\u001b[0m     expected_dtype \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m   1262\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlora_A[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactive_adapter]\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m   1263\u001b[0m     output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1264\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlora_B\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactive_adapter\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1265\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlora_A\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactive_adapter\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlora_dropout\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactive_adapter\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1266\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(expected_dtype)\n\u001b[1;32m   1267\u001b[0m         \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaling[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactive_adapter]\n\u001b[1;32m   1268\u001b[0m     )\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1270\u001b[0m     output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1271\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlora_B[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactive_adapter](\n\u001b[1;32m   1272\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlora_A[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactive_adapter](\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlora_dropout[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactive_adapter](x))\n\u001b[1;32m   1273\u001b[0m         )\n\u001b[1;32m   1274\u001b[0m         \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaling[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactive_adapter]\n\u001b[1;32m   1275\u001b[0m     )\n",
      "File \u001b[0;32m/app/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/app/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/app/venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# repitition_penalty really blows test_df['text'][1] out of the water...`\n",
    "\n",
    "analyze_generation_params(text, persisted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c719fe-4b25-484c-89de-a4906e9f0afa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1483fa13-f183-455e-b4e8-b0e00c3f704d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
